{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2504a981",
   "metadata": {},
   "source": [
    "# Regression \n",
    "\n",
    "Regression is a very old method that calculate the relationship between responses and corresponding explanatory variables.\n",
    "For linear regression analysis, which is always the beginning guess if models are not specified, it present the statistical significance if pvalue is below 5% significance level. \n",
    "\n",
    "\n",
    "\n",
    "# Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5a38fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALIENWARE\\anaconda3\\envs\\tf\\lib\\site-packages\\numba\\np\\ufunc\\parallel.py:365: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 10005. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n",
      "C:\\Users\\ALIENWARE\\anaconda3\\envs\\tf\\lib\\site-packages\\pysal\\explore\\segregation\\network\\network.py:16: UserWarning: You need pandana and urbanaccess to work with segregation's network module\n",
      "You can install them with  `pip install urbanaccess pandana` or `conda install -c udst pandana urbanaccess`\n",
      "  \"You need pandana and urbanaccess to work with segregation's network module\\n\"\n",
      "C:\\Users\\ALIENWARE\\anaconda3\\envs\\tf\\lib\\site-packages\\pysal\\model\\spvcm\\abstracts.py:10: UserWarning: The `dill` module is required to use the sqlite backend fully.\n",
      "  from .sqlite import head_to_sql, start_sql\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialization\n",
    "import dcor\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import pool\n",
    "import geopandas\n",
    "\n",
    "\n",
    "import sys\n",
    "import pysal\n",
    "from pysal.model.spreg import ols, ml_error, ml_lag\n",
    "from libpysal.weights import W\n",
    "import libpysal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "from community import community_louvain as community\n",
    "\n",
    "from dcor._dcor_internals import _u_distance_matrix, u_complementary_projection\n",
    "from sklearn.manifold import MDS\n",
    "import gc\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "std_values = pickle.load(open('C:\\\\Users\\\\ALIENWARE\\\\Desktop\\\\Utils\\\\dict_all_i_wb.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3dbe7c",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdac660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original and standardised data set\n",
    "dict_all = pickle.load(open('C:\\\\Users\\\\ALIENWARE\\\\Desktop\\\\Utils\\\\dict.pkl', 'rb'))\n",
    "dict_all_std = pickle.load(open('C:\\\\Users\\\\ALIENWARE\\\\Desktop\\\\Utils\\\\dict_std.pkl', 'rb'))\n",
    "variable=dict_all_std['Darlington'].index\n",
    "year = dict_all_std['Darlington'].columns\n",
    "\n",
    "# Data Preparation\n",
    "#data preparation\n",
    "continents_prep_g = {}\n",
    "\n",
    "#loading authorityname and dataset\n",
    "EMPLOYMENT = pd.read_csv(\"EMPLOYMENT.csv\",dtype = \"object\",na_values=[\"*\",\"-\",\"!\"],skiprows=6)\n",
    "\n",
    "Employmentall = EMPLOYMENT.dropna(subset=[\"row\"])\n",
    "a = ['row']\n",
    "Employmentall = Employmentall[~Employmentall['row'].isin(a)]\n",
    "Employmentall['year']=0\n",
    "for i in range(17):\n",
    "    Employmentall['year'][i*206:(i+1)*206] = 2004+i\n",
    "\n",
    "#recall authorityname\n",
    "authoritynames = list(Employmentall['local authority: county / unitary (as of April 2021)'].unique())\n",
    "#remove the authority with all nan values\n",
    "authoritynames.remove('Isles of Scilly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb69099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Economic activity rate - aged 16-64', 'Employment rate - aged 16-64',\n",
       "       '% aged 16-64 who are employees', '% aged 16-64 who are self employed',\n",
       "       'Unemployment rate - aged 16-64', 'Unemployment rate - aged 16+',\n",
       "       '% who are economically inactive - aged 16-64',\n",
       "       '% of economically inactive who want a job',\n",
       "       '% of economically inactive who do not want a job',\n",
       "       'Economic activity rate males - aged 16-64',\n",
       "       'Employment rate males - aged 16-64',\n",
       "       '% of males aged 16-64 who are employees',\n",
       "       '% of males aged 16-64 who are self employed',\n",
       "       'Unemployment rate males - aged 16-64',\n",
       "       'Unemployment rate males - aged 16+',\n",
       "       '% of  males who are economically inactive - aged 16-64',\n",
       "       '% of economically inactive males who want a job',\n",
       "       '% of economically inactive males who do not want a job',\n",
       "       'Economic activity rate females - aged 16-64',\n",
       "       'Employment rate females - aged 16-64',\n",
       "       '% of females aged 16-64 who are employees',\n",
       "       '% of females aged 16-64 who are self employed',\n",
       "       'Unemployment rate females - aged 16-64',\n",
       "       'Unemployment rate females - aged 16+',\n",
       "       '% of females who are economically inactive - aged 16-64',\n",
       "       '% of economically inactive females who want a job',\n",
       "       '% of economically inactive females who do not want a job',\n",
       "       '% all in employment who are - 1: managers, directors and senior officials (SOC2010)',\n",
       "       '% all in employment who are - 2: professional occupations (SOC2010)',\n",
       "       '% all in employment who are - 3: associate prof & tech occupations (SOC2010)',\n",
       "       '% all in employment who are - 4: administrative and secretarial occupations (SOC2010)',\n",
       "       '% all in employment who are - 5: skilled trades occupations (SOC2010)',\n",
       "       '% all in employment who are - 6: caring, leisure and other service occupations (SOC2010)',\n",
       "       '% all in employment who are - 7: sales and customer service occupations (SOC2010)',\n",
       "       '% all in employment who are - 8: process, plant and machine operatives (SOC2010)',\n",
       "       '% all in employment who are - 9: elementary occupations (SOC2010)',\n",
       "       'aged 16-64 employment rate - ethnic minority',\n",
       "       '16+ unemployment rate - ethnic minority',\n",
       "       '% of  ethnic minority aged 16-64 who are economically inactive',\n",
       "       '% with NVQ4+ - aged 16-64', '% with NVQ3+ - aged 16-64',\n",
       "       '% with NVQ2+ - aged 16-64', '% with NVQ1+ - aged 16-64',\n",
       "       '% with other qualifications (NVQ) - aged 16-64',\n",
       "       '% with no qualifications (NVQ) - aged 16-64',\n",
       "       '% of all people aged 16+ who are male',\n",
       "       '% of all people aged 16+ who are female',\n",
       "       '% of all people aged 16+ who are aged 16-64', 'earnings',\n",
       "       'earnings_25', 'earnings_75', 'population_density', 'authority_type',\n",
       "       'authority_region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this accounts for all variables with unemployment and earnings\n",
    "variablelen = [0,4, 27, 28, 29, 30, 31,32,33,34,35, 39,-9,-6, -3,-2,-1 ]\n",
    "#number of total variables\n",
    "len(variablelen)\n",
    "\n",
    "#this is all potential x variables excluding unemployment\n",
    "xvariable = [0, 27, 28, 29, 30, 31,32,33,34,35, 39,-9,-6, -3 ]\n",
    "\n",
    "#this is all potential x variables excluding unemployment and median earnings but with upper quantile earnings\n",
    "xvariable_upperquant = [0, 27, 28, 29, 30, 31,32,33,34,35, 39,-9,-4, -3 ]\n",
    "\n",
    "\n",
    "#this is all potential x variables excluding unemployment and median earnings but with lower quantile earnings\n",
    "xvariable_lowerquant = [0, 27, 28, 29, 30, 31,32,33,34,35, 39,-9,-5, -3 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69ca60",
   "metadata": {},
   "source": [
    "# Computation of Pearson and comparison with distance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4f21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define how to calculate pearson correlation\n",
    "def correlation_coefficient(T1, T2):\n",
    "    numerator = np.mean((T1 - T1.mean()) * (T2 - T2.mean()))\n",
    "    denominator = T1.std() * T2.std()\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        result = numerator / denominator\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b9a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearval = range(2008,2021)\n",
    "\n",
    "def distance_cor(row):\n",
    "    #create an empty dataframe\n",
    "    subset = pd.DataFrame(data = np.zeros([len(yearval),3]),columns=['year','dcor','pearson'])\n",
    "    \n",
    "    pair_0, pair_1 = row\n",
    "    #arrange values so that it will become matrices with year as columns and authroity(region) as rows\n",
    "    pair_0_array_all=np.zeros([len(authoritynames),len(yearval)])\n",
    "    pair_1_array_all=np.zeros([len(authoritynames),len(yearval)])\n",
    "    for i in range(len(authoritynames)):\n",
    "        authority = authoritynames[i]\n",
    "        for j in range(len(yearval)):\n",
    "            year = yearval[j]\n",
    "            pair_0_array_all[i,j] = std_values[authority].loc[pair_0,:][year]\n",
    "            pair_1_array_all[i,j] = std_values[authority].loc[pair_1,:][year]\n",
    "    #Calculate distance correlation and pearson correlation\n",
    "    for i in range(len(yearval)):\n",
    "        subset.iloc[i,0] = int(yearval[i])\n",
    "        subset.iloc[i,1] = dcor.distance_correlation(pair_0_array_all[:,i], pair_1_array_all[:,i])\n",
    "        subset.iloc[i,2] = correlation_coefficient(pair_0_array_all[:,i], pair_1_array_all[:,i])\n",
    "    return subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7e7505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>dcor</th>\n",
       "      <th>pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.093099</td>\n",
       "      <td>0.060703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.148761</td>\n",
       "      <td>-0.097950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.152815</td>\n",
       "      <td>-0.143217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.139145</td>\n",
       "      <td>-0.113364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.108170</td>\n",
       "      <td>-0.073862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.165605</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.137641</td>\n",
       "      <td>-0.042503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.120337</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>0.132599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.110169</td>\n",
       "      <td>0.013449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.154683</td>\n",
       "      <td>-0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.178728</td>\n",
       "      <td>-0.129511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.191895</td>\n",
       "      <td>-0.088763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year      dcor   pearson\n",
       "0   2008.0  0.093099  0.060703\n",
       "1   2009.0  0.148761 -0.097950\n",
       "2   2010.0  0.152815 -0.143217\n",
       "3   2011.0  0.139145 -0.113364\n",
       "4   2012.0  0.108170 -0.073862\n",
       "5   2013.0  0.165605  0.045800\n",
       "6   2014.0  0.137641 -0.042503\n",
       "7   2015.0  0.120337  0.000152\n",
       "8   2016.0  0.160805  0.132599\n",
       "9   2017.0  0.110169  0.013449\n",
       "10  2018.0  0.154683 -0.146600\n",
       "11  2019.0  0.178728 -0.129511\n",
       "12  2020.0  0.191895 -0.088763"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemploymentearningsdcor = distance_cor(['Unemployment rate - aged 16-64', 'earnings'])\n",
    "unemploymentearningsdcor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87fb07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise distance correlation of unemployment and earnings for panel data is 0.4334879490979441\n",
      "Pearson correlation of unemployment and earnings for panel data is -0.5721486944912192\n"
     ]
    }
   ],
   "source": [
    "# preparing pair_0 and pair_1\n",
    "             \n",
    "    \n",
    "pair_0_mat=np.zeros([len(authoritynames),len(std_values['Darlington'].loc['earnings',:][4:])])\n",
    "pair_1_mat=np.zeros([len(authoritynames),len(std_values['Darlington'].loc['Unemployment rate - aged 16-64',:][4:])])\n",
    "for ind in range(len(authoritynames)):\n",
    "        #only take 2008 onwards data\n",
    "        pair_0_mat[ind] = std_values[authoritynames[ind]].loc['earnings',:][4:]\n",
    "        pair_1_mat[ind] = std_values[authoritynames[ind]].loc['Unemployment rate - aged 16-64',:][4:]\n",
    "        \n",
    "print(f\"pairwise distance correlation of unemployment and earnings for panel data is {dcor.distance_correlation(pair_0_mat, pair_1_mat)}\")\n",
    "print(f\"Pearson correlation of unemployment and earnings for panel data is {correlation_coefficient(pair_0_mat, pair_1_mat)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a8bd5f",
   "metadata": {},
   "source": [
    "Can easily see that for some year, the distance correlation and the absolute value of pearson correlation are very close to each other whereas some year they are not. This will be quite interesting if we check linear regression can show the similar result of significance of unemployment and earning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56580d1",
   "metadata": {},
   "source": [
    "# Linear regression for unemployment and earning only\n",
    "For all data we have, we consider the relation between unemployment and earning for each year from 2008 to 2020. Now first, take the yvalue to be unemployment and x value to be earnings. Here we define a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6535ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initializationforveclinreg(yeari):\n",
    "    #first, compute yvec corresponding unemployment for year i. Initialize it\n",
    "    yvec = np.zeros([len(authoritynames),1])\n",
    "    #Plug in the values for yvec\n",
    "    for j in range(len(authoritynames)):\n",
    "        #only take yeari data\n",
    "        yvec[j] = std_values[authoritynames[j]].iloc[4,yeari]\n",
    "\n",
    "    #now, compute xvec corresponding earnings for yeari. Initialize it. Note xvec is 205*2 matrix, in which the first column is all ones,\n",
    "    #corresponding to interception. \n",
    "    xvec = np.zeros([len(authoritynames),2])\n",
    "    #Plug in the values for xvec, here the first column all equal to one\n",
    "    xvec[:,0] = 1\n",
    "\n",
    "    for j in range(len(authoritynames)):\n",
    "        #only take yeari data\n",
    "        xvec[j,1] = std_values[authoritynames[j]].iloc[-6,yeari]\n",
    "    return yvec, xvec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7457c",
   "metadata": {},
   "source": [
    "\n",
    "Can first calculate the linear regression for unemployment and earnings in 2008 to have a check: (2008 corresponds to the fourth column of std_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d08067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pvalue between unemployment and earnings is 0.387250606268407\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#Compute the regression using sklearn\n",
    "yvec2008,xvec2008=Initializationforveclinreg(4)\n",
    "resultsvec2008 = sm.OLS(yvec2008,xvec2008).fit()\n",
    "#get the pvalue for coefficient between unemployment and earnings\n",
    "print(f'The pvalue between unemployment and earnings is {resultsvec2008.pvalues[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489a338",
   "metadata": {},
   "source": [
    "Now we compute all the pvalues for year from 2008 to 2020 to compare with the one with distance correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f7f017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38725061, 0.16234764, 0.04050262, 0.10557168, 0.29256493,\n",
       "       0.51434783, 0.54510657, 0.99827726, 0.05805257, 0.8482197 ,\n",
       "       0.03594898, 0.06420104, 0.20564924])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize a vector with 13 years of pvalue\n",
    "linreg_twovar = np.zeros(13)\n",
    "linreg_coeff = np.zeros(13)\n",
    "linreg_se = np.zeros(13)\n",
    "#iterate over years from year 2008 to 2020: (2008 corresponds to 4th column of stdvalue and 2020 corresponds to 17th column of stdvalue)\n",
    "for i in range(4,17):    \n",
    "    #compute all regression using initialized function for xvec and yvec \n",
    "    yvec,xvec = Initializationforveclinreg(i)\n",
    "    resultsvec = sm.OLS(yvec,xvec).fit()\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    linreg_twovar[i-4] = resultsvec.pvalues[1]\n",
    "    linreg_coeff[i-4] = resultsvec.params[1]\n",
    "    linreg_se[i-4] = resultsvec.bse[1]\n",
    "#show the result\n",
    "linreg_twovar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f3f6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>linreg_p_value</th>\n",
       "      <th>standard error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.046773</td>\n",
       "      <td>0.387251</td>\n",
       "      <td>0.053980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>-0.128243</td>\n",
       "      <td>0.162348</td>\n",
       "      <td>0.091451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.234369</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>0.113673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>0.105572</td>\n",
       "      <td>0.096199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>-0.121163</td>\n",
       "      <td>0.292565</td>\n",
       "      <td>0.114819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.083525</td>\n",
       "      <td>0.514348</td>\n",
       "      <td>0.127864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.072123</td>\n",
       "      <td>0.545107</td>\n",
       "      <td>0.118989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>0.106052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.191334</td>\n",
       "      <td>0.058053</td>\n",
       "      <td>0.100381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.848220</td>\n",
       "      <td>0.107485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>-0.193041</td>\n",
       "      <td>0.035949</td>\n",
       "      <td>0.091422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.114748</td>\n",
       "      <td>0.064201</td>\n",
       "      <td>0.061662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.099215</td>\n",
       "      <td>0.205649</td>\n",
       "      <td>0.078141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  coefficient  linreg_p_value  standard error\n",
       "0   2008     0.046773        0.387251        0.053980\n",
       "1   2009    -0.128243        0.162348        0.091451\n",
       "2   2010    -0.234369        0.040503        0.113673\n",
       "3   2011    -0.156387        0.105572        0.096199\n",
       "4   2012    -0.121163        0.292565        0.114819\n",
       "5   2013     0.083525        0.514348        0.127864\n",
       "6   2014    -0.072123        0.545107        0.118989\n",
       "7   2015     0.000229        0.998277        0.106052\n",
       "8   2016     0.191334        0.058053        0.100381\n",
       "9   2017     0.020598        0.848220        0.107485\n",
       "10  2018    -0.193041        0.035949        0.091422\n",
       "11  2019    -0.114748        0.064201        0.061662\n",
       "12  2020    -0.099215        0.205649        0.078141"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an empty dataframe\n",
    "linreg_twovardf = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),4]),columns=['year','coefficient','linreg_p_value','standard error'])\n",
    "#Plug values into dataframe to make a better visualization of the result\n",
    "linreg_twovardf.iloc[:,0] = list(range(2008,2021))\n",
    "linreg_twovardf.iloc[:,1] = linreg_coeff\n",
    "linreg_twovardf.iloc[:,2] = linreg_twovar\n",
    "linreg_twovardf.iloc[:,3] = linreg_se\n",
    "\n",
    "linreg_twovardf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9cdc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Error bar plotting for coefficient over time')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot()\n",
    "plt.errorbar(linreg_twovardf.iloc[:,0], linreg_twovardf.iloc[:,1], yerr = linreg_twovardf.iloc[:,3],fmt = 'o',color = 'black', \n",
    "            ecolor = 'orange', capsize=3)\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.title(\"Error bar plotting for coefficient over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86e0a7",
   "metadata": {},
   "source": [
    "# Linear regression for year 2020 with respect to other variables\n",
    "\n",
    "Suppose now we only interested in 2020 unemployment and its relationship with other condition variables in the year and see if correlation between unemployment and earnings is still correlated. We take the xvariable as indicated in data preparation part. Now we can get all the values as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95694a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, compute ymat corresponding unemployment for year 2020. Initialize it\n",
    "ymat2020 = np.zeros([len(authoritynames),1])\n",
    "#Plug in the values for yvec\n",
    "for j in range(len(authoritynames)):\n",
    "    #only take yeari data\n",
    "    ymat2020[j] = std_values[authoritynames[j]].iloc[4,-1]\n",
    "\n",
    "#now, compute xmat corresponding earnings for 2020. Initialize it. Note  is 205*2 matrix, in which the first column is all ones,\n",
    "#corresponding to interception. \n",
    "xmat2020 = np.zeros([len(authoritynames),len(xvariable)])\n",
    "#initialize the first column as all ones\n",
    "xmat2020[:,0] = 1\n",
    "#xmat has rows with authorities and columns as xvariables\n",
    "for j in range(len(xvariable)):\n",
    "    for i in range(len(authoritynames)):\n",
    "        #only take 2020\n",
    "        xmat2020[i,j] = std_values[authoritynames[i]].iloc[xvariable[j],-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf224d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   12.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 12 Jun 2022</td> <th>  Prob (F-statistic):</th>          <td>7.85e-20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:57:57</td>     <th>  Log-Likelihood:    </th>          <td> -232.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   205</td>      <th>  AIC:               </th>          <td>   492.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   191</td>      <th>  BIC:               </th>          <td>   538.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.0203</td> <td>    0.046</td> <td>    0.439</td> <td> 0.661</td> <td>   -0.071</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   -0.0550</td> <td>    0.064</td> <td>   -0.865</td> <td> 0.388</td> <td>   -0.180</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.0245</td> <td>    0.088</td> <td>    0.279</td> <td> 0.781</td> <td>   -0.149</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -0.1449</td> <td>    0.070</td> <td>   -2.076</td> <td> 0.039</td> <td>   -0.282</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>   -0.0547</td> <td>    0.069</td> <td>   -0.790</td> <td> 0.431</td> <td>   -0.192</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   -0.0211</td> <td>    0.065</td> <td>   -0.326</td> <td> 0.745</td> <td>   -0.149</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>   -0.0294</td> <td>    0.057</td> <td>   -0.517</td> <td> 0.606</td> <td>   -0.142</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -0.0223</td> <td>    0.057</td> <td>   -0.392</td> <td> 0.696</td> <td>   -0.135</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.0054</td> <td>    0.059</td> <td>    0.092</td> <td> 0.926</td> <td>   -0.110</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   -0.0777</td> <td>    0.060</td> <td>   -1.294</td> <td> 0.197</td> <td>   -0.196</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   -0.2154</td> <td>    0.104</td> <td>   -2.079</td> <td> 0.039</td> <td>   -0.420</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0369</td> <td>    0.025</td> <td>    1.450</td> <td> 0.149</td> <td>   -0.013</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -0.1454</td> <td>    0.065</td> <td>   -2.219</td> <td> 0.028</td> <td>   -0.275</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>   -0.0083</td> <td>    0.069</td> <td>   -0.121</td> <td> 0.904</td> <td>   -0.143</td> <td>    0.127</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>23.027</td> <th>  Durbin-Watson:     </th> <td>   1.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  30.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.725</td> <th>  Prob(JB):          </th> <td>2.55e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.204</td> <th>  Cond. No.          </th> <td>    11.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.469\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.430\n",
       "Method:                 Least Squares   F-statistic:                              12.07\n",
       "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    7.85e-20\n",
       "Time:                        23:57:57   Log-Likelihood:                         -232.04\n",
       "No. Observations:                 205   AIC:                                      492.1\n",
       "Df Residuals:                     191   BIC:                                      538.6\n",
       "Df Model:                          14                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0203      0.046      0.439      0.661      -0.071       0.112\n",
       "x2            -0.0550      0.064     -0.865      0.388      -0.180       0.070\n",
       "x3             0.0245      0.088      0.279      0.781      -0.149       0.198\n",
       "x4            -0.1449      0.070     -2.076      0.039      -0.282      -0.007\n",
       "x5            -0.0547      0.069     -0.790      0.431      -0.192       0.082\n",
       "x6            -0.0211      0.065     -0.326      0.745      -0.149       0.107\n",
       "x7            -0.0294      0.057     -0.517      0.606      -0.142       0.083\n",
       "x8            -0.0223      0.057     -0.392      0.696      -0.135       0.090\n",
       "x9             0.0054      0.059      0.092      0.926      -0.110       0.121\n",
       "x10           -0.0777      0.060     -1.294      0.197      -0.196       0.041\n",
       "x11           -0.2154      0.104     -2.079      0.039      -0.420      -0.011\n",
       "x12            0.0369      0.025      1.450      0.149      -0.013       0.087\n",
       "x13           -0.1454      0.065     -2.219      0.028      -0.275      -0.016\n",
       "x14           -0.0083      0.069     -0.121      0.904      -0.143       0.127\n",
       "==============================================================================\n",
       "Omnibus:                       23.027   Durbin-Watson:                   1.979\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.364\n",
       "Skew:                           0.725   Prob(JB):                     2.55e-07\n",
       "Kurtosis:                       4.204   Cond. No.                         11.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the regression using sm\n",
    "resultsvec2020 = sm.OLS(ymat2020,xmat2020).fit()\n",
    "resultsvec2020.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52710e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pvalue between unemployment and earnings is 0.02763600314575705\n"
     ]
    }
   ],
   "source": [
    "print(f'The pvalue between unemployment and earnings is {resultsvec2020.pvalues[-2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6a5c2",
   "metadata": {},
   "source": [
    "# Linear regression for all years with respect to other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "044258d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearlinreg(year):\n",
    "    #first, compute ymat corresponding unemployment for year 2020. Initialize it\n",
    "    ymat = np.zeros([len(authoritynames),1])\n",
    "    #Plug in the values for yvec\n",
    "    for j in range(len(authoritynames)):\n",
    "        #only take yeari data\n",
    "        ymat[j] = std_values[authoritynames[j]].iloc[4,year]\n",
    "\n",
    "    #now, compute xmat corresponding earnings for 2020. Initialize it. Note  is 205*len(xvariable) matrix, in which the first column is all ones,\n",
    "    #corresponding to interception. \n",
    "    xmat = np.zeros([len(authoritynames),len(xvariable)])\n",
    "    #initialize the first column as all ones\n",
    "    xmat[:,0] = 1\n",
    "    #xmat has rows with authorities and columns as xvariables\n",
    "    for j in range(len(xvariable)):\n",
    "        for i in range(len(authoritynames)):\n",
    "            #only take 2020\n",
    "            xmat[i,j] = std_values[authoritynames[i]].iloc[xvariable[j],year]\n",
    "    return ymat,xmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b689ba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2008 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.058\n",
      "Model:                            OLS   Adj. R-squared (uncentered):             -0.012\n",
      "Method:                 Least Squares   F-statistic:                             0.8331\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                       0.633\n",
      "Time:                        23:57:57   Log-Likelihood:                         -159.23\n",
      "No. Observations:                 205   AIC:                                      346.5\n",
      "Df Residuals:                     191   BIC:                                      393.0\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0166      0.049     -0.342      0.733      -0.112       0.079\n",
      "x2            -0.0364      0.070     -0.521      0.603      -0.174       0.101\n",
      "x3             0.0364      0.106      0.344      0.731      -0.172       0.245\n",
      "x4            -0.0833      0.073     -1.146      0.253      -0.227       0.060\n",
      "x5            -0.0181      0.079     -0.230      0.819      -0.174       0.138\n",
      "x6            -0.0519      0.073     -0.712      0.477      -0.196       0.092\n",
      "x7            -0.0535      0.071     -0.753      0.452      -0.194       0.087\n",
      "x8            -0.0478      0.063     -0.760      0.448      -0.172       0.076\n",
      "x9            -0.0797      0.060     -1.337      0.183      -0.197       0.038\n",
      "x10            0.0305      0.076      0.402      0.688      -0.119       0.180\n",
      "x11           -0.0718      0.099     -0.727      0.468      -0.266       0.123\n",
      "x12            0.0110      0.057      0.193      0.847      -0.101       0.123\n",
      "x13            0.0759      0.046      1.654      0.100      -0.015       0.166\n",
      "x14           -0.0422      0.084     -0.500      0.617      -0.209       0.124\n",
      "==============================================================================\n",
      "Omnibus:                        0.129   Durbin-Watson:                   1.961\n",
      "Prob(Omnibus):                  0.937   Jarque-Bera (JB):                0.220\n",
      "Skew:                          -0.055   Prob(JB):                        0.896\n",
      "Kurtosis:                       2.883   Cond. No.                         10.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2009 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.747\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.729\n",
      "Method:                 Least Squares   F-statistic:                              40.37\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    1.99e-49\n",
      "Time:                        23:57:58   Log-Likelihood:                         -198.76\n",
      "No. Observations:                 205   AIC:                                      425.5\n",
      "Df Residuals:                     191   BIC:                                      472.0\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0701      0.062     -1.126      0.262      -0.193       0.053\n",
      "x2             0.1002      0.079      1.263      0.208      -0.056       0.257\n",
      "x3             0.2794      0.120      2.325      0.021       0.042       0.516\n",
      "x4             0.1926      0.090      2.140      0.034       0.015       0.370\n",
      "x5             0.1965      0.086      2.295      0.023       0.028       0.365\n",
      "x6             0.0212      0.083      0.254      0.800      -0.143       0.186\n",
      "x7             0.2312      0.076      3.028      0.003       0.081       0.382\n",
      "x8             0.0431      0.074      0.578      0.564      -0.104       0.190\n",
      "x9             0.0323      0.075      0.433      0.666      -0.115       0.179\n",
      "x10            0.1940      0.085      2.289      0.023       0.027       0.361\n",
      "x11           -0.7935      0.116     -6.831      0.000      -1.023      -0.564\n",
      "x12           -0.0039      0.071     -0.055      0.956      -0.143       0.135\n",
      "x13           -0.4832      0.078     -6.219      0.000      -0.636      -0.330\n",
      "x14           -0.2796      0.116     -2.415      0.017      -0.508      -0.051\n",
      "==============================================================================\n",
      "Omnibus:                       16.237   Durbin-Watson:                   1.667\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.210\n",
      "Skew:                          -0.502   Prob(JB):                     9.12e-06\n",
      "Kurtosis:                       4.308   Cond. No.                         6.78\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2010 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.690\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.667\n",
      "Method:                 Least Squares   F-statistic:                              30.33\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    4.15e-41\n",
      "Time:                        23:57:58   Log-Likelihood:                         -219.04\n",
      "No. Observations:                 205   AIC:                                      466.1\n",
      "Df Residuals:                     191   BIC:                                      512.6\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0446      0.059     -0.751      0.454      -0.162       0.073\n",
      "x2             0.1290      0.087      1.476      0.142      -0.043       0.301\n",
      "x3             0.1514      0.136      1.115      0.266      -0.116       0.419\n",
      "x4             0.0385      0.100      0.384      0.701      -0.159       0.236\n",
      "x5            -0.0446      0.109     -0.410      0.682      -0.259       0.170\n",
      "x6            -0.0167      0.091     -0.184      0.854      -0.196       0.163\n",
      "x7             0.0864      0.091      0.947      0.345      -0.094       0.266\n",
      "x8             0.0382      0.082      0.467      0.641      -0.123       0.200\n",
      "x9            -0.0231      0.088     -0.263      0.793      -0.197       0.150\n",
      "x10            0.1455      0.099      1.464      0.145      -0.051       0.342\n",
      "x11           -0.5389      0.156     -3.448      0.001      -0.847      -0.231\n",
      "x12            0.0135      0.059      0.229      0.819      -0.103       0.130\n",
      "x13           -0.5702      0.083     -6.862      0.000      -0.734      -0.406\n",
      "x14           -0.7115      0.137     -5.179      0.000      -0.983      -0.441\n",
      "==============================================================================\n",
      "Omnibus:                        5.284   Durbin-Watson:                   1.964\n",
      "Prob(Omnibus):                  0.071   Jarque-Bera (JB):                5.030\n",
      "Skew:                           0.307   Prob(JB):                       0.0809\n",
      "Kurtosis:                       3.461   Cond. No.                         6.83\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2011 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.722\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.702\n",
      "Method:                 Least Squares   F-statistic:                              35.49\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    1.36e-45\n",
      "Time:                        23:57:58   Log-Likelihood:                         -235.74\n",
      "No. Observations:                 205   AIC:                                      499.5\n",
      "Df Residuals:                     191   BIC:                                      546.0\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.1657      0.067     -2.458      0.015      -0.299      -0.033\n",
      "x2            -0.0623      0.083     -0.750      0.454      -0.226       0.102\n",
      "x3             0.0667      0.132      0.505      0.614      -0.194       0.328\n",
      "x4            -0.0465      0.101     -0.462      0.645      -0.245       0.152\n",
      "x5            -0.0927      0.115     -0.805      0.422      -0.320       0.135\n",
      "x6            -0.1091      0.097     -1.127      0.261      -0.300       0.082\n",
      "x7            -0.0642      0.090     -0.715      0.476      -0.241       0.113\n",
      "x8            -0.0383      0.083     -0.463      0.644      -0.201       0.125\n",
      "x9            -0.0731      0.087     -0.842      0.401      -0.244       0.098\n",
      "x10           -0.0077      0.097     -0.080      0.936      -0.198       0.183\n",
      "x11           -0.5890      0.164     -3.593      0.000      -0.912      -0.266\n",
      "x12            0.0277      0.074      0.374      0.709      -0.118       0.174\n",
      "x13           -0.9412      0.078    -12.040      0.000      -1.095      -0.787\n",
      "x14           -0.0269      0.130     -0.206      0.837      -0.284       0.230\n",
      "==============================================================================\n",
      "Omnibus:                        0.589   Durbin-Watson:                   1.920\n",
      "Prob(Omnibus):                  0.745   Jarque-Bera (JB):                0.683\n",
      "Skew:                          -0.121   Prob(JB):                        0.711\n",
      "Kurtosis:                       2.853   Cond. No.                         6.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2012 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.607\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.578\n",
      "Method:                 Least Squares   F-statistic:                              21.04\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    1.34e-31\n",
      "Time:                        23:57:58   Log-Likelihood:                         -259.76\n",
      "No. Observations:                 205   AIC:                                      547.5\n",
      "Df Residuals:                     191   BIC:                                      594.0\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0363      0.075      0.484      0.629      -0.111       0.184\n",
      "x2            -0.1323      0.110     -1.200      0.232      -0.350       0.085\n",
      "x3            -0.2014      0.145     -1.387      0.167      -0.488       0.085\n",
      "x4            -0.1279      0.121     -1.060      0.290      -0.366       0.110\n",
      "x5            -0.3231      0.132     -2.441      0.016      -0.584      -0.062\n",
      "x6            -0.0659      0.114     -0.576      0.565      -0.292       0.160\n",
      "x7            -0.0836      0.098     -0.857      0.392      -0.276       0.109\n",
      "x8            -0.0765      0.107     -0.713      0.477      -0.288       0.135\n",
      "x9            -0.2269      0.103     -2.197      0.029      -0.431      -0.023\n",
      "x10           -0.0291      0.114     -0.256      0.798      -0.253       0.195\n",
      "x11           -0.1533      0.186     -0.823      0.412      -0.521       0.214\n",
      "x12           -0.1187      0.093     -1.276      0.204      -0.302       0.065\n",
      "x13           -1.2974      0.100    -13.028      0.000      -1.494      -1.101\n",
      "x14            0.1075      0.166      0.647      0.518      -0.220       0.435\n",
      "==============================================================================\n",
      "Omnibus:                        0.956   Durbin-Watson:                   1.601\n",
      "Prob(Omnibus):                  0.620   Jarque-Bera (JB):                0.883\n",
      "Skew:                          -0.160   Prob(JB):                        0.643\n",
      "Kurtosis:                       2.977   Cond. No.                         5.26\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2013 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.444\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.404\n",
      "Method:                 Least Squares   F-statistic:                              10.91\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    4.69e-18\n",
      "Time:                        23:57:58   Log-Likelihood:                         -264.68\n",
      "No. Observations:                 205   AIC:                                      557.4\n",
      "Df Residuals:                     191   BIC:                                      603.9\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0983      0.074      1.322      0.188      -0.048       0.245\n",
      "x2            -0.1718      0.101     -1.704      0.090      -0.371       0.027\n",
      "x3            -0.3011      0.163     -1.852      0.066      -0.622       0.020\n",
      "x4            -0.2806      0.109     -2.574      0.011      -0.496      -0.066\n",
      "x5            -0.1877      0.130     -1.447      0.150      -0.444       0.068\n",
      "x6            -0.2901      0.113     -2.573      0.011      -0.512      -0.068\n",
      "x7            -0.1127      0.106     -1.058      0.291      -0.323       0.097\n",
      "x8            -0.0921      0.108     -0.853      0.395      -0.305       0.121\n",
      "x9            -0.1546      0.095     -1.626      0.106      -0.342       0.033\n",
      "x10           -0.1436      0.116     -1.238      0.217      -0.373       0.085\n",
      "x11            0.4029      0.178      2.267      0.025       0.052       0.754\n",
      "x12            0.1877      0.101      1.854      0.065      -0.012       0.387\n",
      "x13           -0.8910      0.128     -6.964      0.000      -1.143      -0.639\n",
      "x14            0.2503      0.181      1.383      0.168      -0.107       0.607\n",
      "==============================================================================\n",
      "Omnibus:                       13.233   Durbin-Watson:                   1.744\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               13.963\n",
      "Skew:                          -0.580   Prob(JB):                     0.000929\n",
      "Kurtosis:                       3.537   Cond. No.                         5.24\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2014 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.205\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.147\n",
      "Method:                 Least Squares   F-statistic:                              3.515\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    3.90e-05\n",
      "Time:                        23:57:58   Log-Likelihood:                         -183.24\n",
      "No. Observations:                 205   AIC:                                      394.5\n",
      "Df Residuals:                     191   BIC:                                      441.0\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0350      0.053     -0.665      0.507      -0.139       0.069\n",
      "x2             0.0705      0.072      0.975      0.331      -0.072       0.213\n",
      "x3            -0.0368      0.112     -0.328      0.744      -0.259       0.185\n",
      "x4            -0.0859      0.088     -0.973      0.332      -0.260       0.088\n",
      "x5            -0.1001      0.083     -1.212      0.227      -0.263       0.063\n",
      "x6             0.0513      0.081      0.637      0.525      -0.108       0.210\n",
      "x7            -0.0146      0.071     -0.204      0.838      -0.156       0.126\n",
      "x8            -0.0394      0.070     -0.563      0.574      -0.177       0.098\n",
      "x9            -0.0945      0.064     -1.479      0.141      -0.221       0.032\n",
      "x10           -0.0632      0.073     -0.863      0.389      -0.208       0.081\n",
      "x11           -0.0524      0.115     -0.455      0.649      -0.280       0.175\n",
      "x12            0.0144      0.058      0.250      0.803      -0.099       0.128\n",
      "x13           -0.3267      0.109     -3.006      0.003      -0.541      -0.112\n",
      "x14            0.2239      0.131      1.707      0.090      -0.035       0.483\n",
      "==============================================================================\n",
      "Omnibus:                        2.722   Durbin-Watson:                   1.656\n",
      "Prob(Omnibus):                  0.256   Jarque-Bera (JB):                2.768\n",
      "Skew:                           0.251   Prob(JB):                        0.251\n",
      "Kurtosis:                       2.733   Cond. No.                         5.80\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2015 has result:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.221\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.164\n",
      "Method:                 Least Squares   F-statistic:                              3.867\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    8.57e-06\n",
      "Time:                        23:57:58   Log-Likelihood:                         -170.59\n",
      "No. Observations:                 205   AIC:                                      369.2\n",
      "Df Residuals:                     191   BIC:                                      415.7\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0556      0.048      1.164      0.246      -0.039       0.150\n",
      "x2            -0.0432      0.066     -0.650      0.516      -0.174       0.088\n",
      "x3            -0.1637      0.105     -1.566      0.119      -0.370       0.043\n",
      "x4            -0.0487      0.079     -0.616      0.539      -0.205       0.107\n",
      "x5             0.0607      0.078      0.779      0.437      -0.093       0.214\n",
      "x6            -0.0835      0.067     -1.250      0.213      -0.215       0.048\n",
      "x7             0.0172      0.065      0.264      0.792      -0.111       0.145\n",
      "x8            -0.1043      0.065     -1.593      0.113      -0.233       0.025\n",
      "x9            -0.0714      0.064     -1.110      0.269      -0.198       0.056\n",
      "x10           -0.0507      0.072     -0.703      0.483      -0.193       0.092\n",
      "x11           -0.1895      0.100     -1.890      0.060      -0.387       0.008\n",
      "x12           -0.0920      0.052     -1.758      0.080      -0.195       0.011\n",
      "x13           -0.0244      0.108     -0.225      0.822      -0.238       0.189\n",
      "x14           -0.1805      0.099     -1.826      0.069      -0.375       0.015\n",
      "==============================================================================\n",
      "Omnibus:                        0.283   Durbin-Watson:                   1.546\n",
      "Prob(Omnibus):                  0.868   Jarque-Bera (JB):                0.171\n",
      "Skew:                           0.069   Prob(JB):                        0.918\n",
      "Kurtosis:                       3.031   Cond. No.                         6.35\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2016 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.415\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.372\n",
      "Method:                 Least Squares   F-statistic:                              9.680\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    4.21e-16\n",
      "Time:                        23:57:59   Log-Likelihood:                         -189.46\n",
      "No. Observations:                 205   AIC:                                      406.9\n",
      "Df Residuals:                     191   BIC:                                      453.4\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0099      0.048     -0.206      0.837      -0.104       0.085\n",
      "x2            -0.1599      0.082     -1.952      0.052      -0.321       0.002\n",
      "x3            -0.1999      0.106     -1.877      0.062      -0.410       0.010\n",
      "x4            -0.2036      0.082     -2.473      0.014      -0.366      -0.041\n",
      "x5            -0.1562      0.083     -1.886      0.061      -0.320       0.007\n",
      "x6            -0.1611      0.079     -2.047      0.042      -0.316      -0.006\n",
      "x7            -0.2198      0.072     -3.073      0.002      -0.361      -0.079\n",
      "x8            -0.1539      0.064     -2.394      0.018      -0.281      -0.027\n",
      "x9            -0.1470      0.071     -2.062      0.041      -0.288      -0.006\n",
      "x10           -0.1642      0.075     -2.203      0.029      -0.311      -0.017\n",
      "x11           -0.3373      0.112     -3.023      0.003      -0.557      -0.117\n",
      "x12           -0.0402      0.052     -0.775      0.440      -0.143       0.062\n",
      "x13            0.0925      0.105      0.881      0.380      -0.115       0.299\n",
      "x14           -0.2388      0.094     -2.536      0.012      -0.424      -0.053\n",
      "==============================================================================\n",
      "Omnibus:                       20.832   Durbin-Watson:                   1.862\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.288\n",
      "Skew:                           0.634   Prob(JB):                     4.37e-07\n",
      "Kurtosis:                       4.350   Cond. No.                         7.54\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2017 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.597\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.567\n",
      "Method:                 Least Squares   F-statistic:                              20.17\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    1.38e-30\n",
      "Time:                        23:57:59   Log-Likelihood:                         -200.66\n",
      "No. Observations:                 205   AIC:                                      429.3\n",
      "Df Residuals:                     191   BIC:                                      475.9\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0283      0.055      0.518      0.605      -0.079       0.136\n",
      "x2            -0.0902      0.082     -1.102      0.272      -0.252       0.071\n",
      "x3            -0.0446      0.108     -0.413      0.680      -0.257       0.168\n",
      "x4            -0.1377      0.086     -1.593      0.113      -0.308       0.033\n",
      "x5            -0.0622      0.095     -0.657      0.512      -0.249       0.124\n",
      "x6            -0.0549      0.077     -0.717      0.474      -0.206       0.096\n",
      "x7            -0.0936      0.068     -1.385      0.168      -0.227       0.040\n",
      "x8            -0.0624      0.071     -0.885      0.377      -0.202       0.077\n",
      "x9             0.0786      0.074      1.067      0.287      -0.067       0.224\n",
      "x10           -0.0799      0.080     -0.994      0.322      -0.238       0.079\n",
      "x11           -0.3303      0.109     -3.031      0.003      -0.545      -0.115\n",
      "x12           -0.1392      0.060     -2.313      0.022      -0.258      -0.021\n",
      "x13           -0.1011      0.111     -0.907      0.366      -0.321       0.119\n",
      "x14           -0.3426      0.085     -4.035      0.000      -0.510      -0.175\n",
      "==============================================================================\n",
      "Omnibus:                        4.403   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.111   Jarque-Bera (JB):                4.030\n",
      "Skew:                           0.287   Prob(JB):                        0.133\n",
      "Kurtosis:                       3.378   Cond. No.                         8.50\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2018 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.676\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.653\n",
      "Method:                 Least Squares   F-statistic:                              28.53\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    2.02e-39\n",
      "Time:                        23:57:59   Log-Likelihood:                         -192.67\n",
      "No. Observations:                 205   AIC:                                      413.3\n",
      "Df Residuals:                     191   BIC:                                      459.9\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0877      0.049     -1.797      0.074      -0.184       0.009\n",
      "x2             0.0162      0.066      0.245      0.807      -0.114       0.147\n",
      "x3             0.0770      0.096      0.800      0.425      -0.113       0.267\n",
      "x4             0.0563      0.074      0.761      0.448      -0.090       0.202\n",
      "x5             0.0503      0.078      0.644      0.520      -0.104       0.204\n",
      "x6             0.0138      0.071      0.194      0.846      -0.126       0.154\n",
      "x7             0.0577      0.067      0.864      0.389      -0.074       0.189\n",
      "x8             0.0149      0.066      0.225      0.822      -0.116       0.146\n",
      "x9             0.0287      0.064      0.448      0.655      -0.098       0.155\n",
      "x10           -0.0585      0.068     -0.860      0.391      -0.193       0.076\n",
      "x11           -0.4346      0.104     -4.178      0.000      -0.640      -0.229\n",
      "x12           -0.0902      0.048     -1.864      0.064      -0.186       0.005\n",
      "x13           -0.3309      0.089     -3.734      0.000      -0.506      -0.156\n",
      "x14           -0.0798      0.078     -1.028      0.305      -0.233       0.073\n",
      "==============================================================================\n",
      "Omnibus:                       22.414   Durbin-Watson:                   1.908\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.365\n",
      "Skew:                           0.678   Prob(JB):                     1.55e-07\n",
      "Kurtosis:                       4.354   Cond. No.                         9.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2019 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.774\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.757\n",
      "Method:                 Least Squares   F-statistic:                              46.73\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    5.87e-54\n",
      "Time:                        23:57:59   Log-Likelihood:                         -180.63\n",
      "No. Observations:                 205   AIC:                                      389.3\n",
      "Df Residuals:                     191   BIC:                                      435.8\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0701      0.048      1.468      0.144      -0.024       0.164\n",
      "x2            -0.0345      0.063     -0.550      0.583      -0.158       0.089\n",
      "x3             0.0662      0.081      0.820      0.414      -0.093       0.226\n",
      "x4            -0.0529      0.063     -0.847      0.398      -0.176       0.070\n",
      "x5             0.0917      0.066      1.389      0.166      -0.039       0.222\n",
      "x6            -0.0158      0.063     -0.250      0.803      -0.140       0.109\n",
      "x7             0.0158      0.059      0.268      0.789      -0.101       0.132\n",
      "x8            -0.0026      0.056     -0.047      0.963      -0.114       0.108\n",
      "x9             0.0204      0.056      0.364      0.716      -0.090       0.131\n",
      "x10           -0.0436      0.066     -0.658      0.511      -0.174       0.087\n",
      "x11           -0.4563      0.100     -4.545      0.000      -0.654      -0.258\n",
      "x12           -0.0648      0.046     -1.403      0.162      -0.156       0.026\n",
      "x13           -0.2499      0.060     -4.162      0.000      -0.368      -0.131\n",
      "x14           -0.0796      0.066     -1.203      0.230      -0.210       0.051\n",
      "==============================================================================\n",
      "Omnibus:                        2.055   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.358   Jarque-Bera (JB):                1.686\n",
      "Skew:                           0.196   Prob(JB):                        0.430\n",
      "Kurtosis:                       3.211   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Year 2020 has result:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.469\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.430\n",
      "Method:                 Least Squares   F-statistic:                              12.07\n",
      "Date:                Sun, 12 Jun 2022   Prob (F-statistic):                    7.85e-20\n",
      "Time:                        23:57:59   Log-Likelihood:                         -232.04\n",
      "No. Observations:                 205   AIC:                                      492.1\n",
      "Df Residuals:                     191   BIC:                                      538.6\n",
      "Df Model:                          14                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0203      0.046      0.439      0.661      -0.071       0.112\n",
      "x2            -0.0550      0.064     -0.865      0.388      -0.180       0.070\n",
      "x3             0.0245      0.088      0.279      0.781      -0.149       0.198\n",
      "x4            -0.1449      0.070     -2.076      0.039      -0.282      -0.007\n",
      "x5            -0.0547      0.069     -0.790      0.431      -0.192       0.082\n",
      "x6            -0.0211      0.065     -0.326      0.745      -0.149       0.107\n",
      "x7            -0.0294      0.057     -0.517      0.606      -0.142       0.083\n",
      "x8            -0.0223      0.057     -0.392      0.696      -0.135       0.090\n",
      "x9             0.0054      0.059      0.092      0.926      -0.110       0.121\n",
      "x10           -0.0777      0.060     -1.294      0.197      -0.196       0.041\n",
      "x11           -0.2154      0.104     -2.079      0.039      -0.420      -0.011\n",
      "x12            0.0369      0.025      1.450      0.149      -0.013       0.087\n",
      "x13           -0.1454      0.065     -2.219      0.028      -0.275      -0.016\n",
      "x14           -0.0083      0.069     -0.121      0.904      -0.143       0.127\n",
      "==============================================================================\n",
      "Omnibus:                       23.027   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.364\n",
      "Skew:                           0.725   Prob(JB):                     2.55e-07\n",
      "Kurtosis:                       4.204   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Initialize a dataframe with 13 years of pvalue\n",
    "linreg_twovarincomedf = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),4]),columns=['year','wages_coefficient','wages_linreg_p_value','standard error'])\n",
    "linreg_twovarincomedf.iloc[:,0] = list(range(2008,2021))\n",
    "\n",
    "for i in range(13):\n",
    "    ymat,xmat = yearlinreg(4+i)\n",
    "    #Compute the regression using sm\n",
    "    resultsvec = sm.OLS(ymat,xmat).fit()\n",
    "    print(f'Year {2008+i} has result:')\n",
    "    print(resultsvec.summary())\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    linreg_twovarincomedf.iloc[i,1] = resultsvec.params[-2]\n",
    "    linreg_twovarincomedf.iloc[i,2] = resultsvec.pvalues[-2]\n",
    "    linreg_twovarincomedf.iloc[i,3] = resultsvec.bse[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff1f4c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>wages_coefficient</th>\n",
       "      <th>wages_linreg_p_value</th>\n",
       "      <th>standard error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.075874</td>\n",
       "      <td>9.973508e-02</td>\n",
       "      <td>0.045868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>-0.483154</td>\n",
       "      <td>3.080526e-09</td>\n",
       "      <td>0.077686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.570242</td>\n",
       "      <td>9.195579e-11</td>\n",
       "      <td>0.083097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>-0.941236</td>\n",
       "      <td>3.309644e-25</td>\n",
       "      <td>0.078179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>-1.297439</td>\n",
       "      <td>3.541845e-28</td>\n",
       "      <td>0.099587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>-0.891028</td>\n",
       "      <td>5.192283e-11</td>\n",
       "      <td>0.127953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.326688</td>\n",
       "      <td>3.005120e-03</td>\n",
       "      <td>0.108688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>8.220004e-01</td>\n",
       "      <td>0.108240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.092453</td>\n",
       "      <td>3.795306e-01</td>\n",
       "      <td>0.104964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>-0.101073</td>\n",
       "      <td>3.657401e-01</td>\n",
       "      <td>0.111481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>-0.330884</td>\n",
       "      <td>2.490950e-04</td>\n",
       "      <td>0.088625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.249930</td>\n",
       "      <td>4.767756e-05</td>\n",
       "      <td>0.060050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.145354</td>\n",
       "      <td>2.763600e-02</td>\n",
       "      <td>0.065492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  wages_coefficient  wages_linreg_p_value  standard error\n",
       "0   2008           0.075874          9.973508e-02        0.045868\n",
       "1   2009          -0.483154          3.080526e-09        0.077686\n",
       "2   2010          -0.570242          9.195579e-11        0.083097\n",
       "3   2011          -0.941236          3.309644e-25        0.078179\n",
       "4   2012          -1.297439          3.541845e-28        0.099587\n",
       "5   2013          -0.891028          5.192283e-11        0.127953\n",
       "6   2014          -0.326688          3.005120e-03        0.108688\n",
       "7   2015          -0.024385          8.220004e-01        0.108240\n",
       "8   2016           0.092453          3.795306e-01        0.104964\n",
       "9   2017          -0.101073          3.657401e-01        0.111481\n",
       "10  2018          -0.330884          2.490950e-04        0.088625\n",
       "11  2019          -0.249930          4.767756e-05        0.060050\n",
       "12  2020          -0.145354          2.763600e-02        0.065492"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_twovarincomedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01d24ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Error bar plotting for coefficient over time')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot()\n",
    "plt.errorbar(linreg_twovarincomedf.iloc[:,0], linreg_twovarincomedf.iloc[:,1], yerr = linreg_twovarincomedf.iloc[:,3],fmt = 'o',color = 'black', \n",
    "            ecolor = 'orange', capsize=3)\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.title(\"Error bar plotting for coefficient over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be309e14",
   "metadata": {},
   "source": [
    "# Linear regression for unemployment and higher income/ lower income earning\n",
    "Here we get the result for lower earnings. We take the regression pvalue for 25% quantile of earnings and make distance correlation with unemployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22f614c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a function for highincome and lowincome \n",
    "def Initializationforveclinreghighincomelowincome(yeari,highincome=False,lowincome=False):\n",
    "    if highincome == True:\n",
    "        xvar = xvariable_upperquant\n",
    "    elif lowincome == True:\n",
    "        xvar = xvariable_lowerquant\n",
    "        \n",
    "    #first, compute yvec corresponding unemployment for year i. Initialize it\n",
    "    yvec = np.zeros([len(authoritynames),1])\n",
    "    #Plug in the values for yvec\n",
    "    for j in range(len(authoritynames)):\n",
    "        #only take yeari data\n",
    "        yvec[j] = std_values[authoritynames[j]].iloc[4,yeari]\n",
    "\n",
    "    #now, compute xvec corresponding earnings for yeari. Initialize it. Note xvec is 205*2 matrix, in which the first column is all ones,\n",
    "    #corresponding to interception. \n",
    "    xmat = np.zeros([len(authoritynames),len(xvariable)])\n",
    "    #Plug in the values for xvec, here the first column all equal to one\n",
    "    xmat[:,0] = 1\n",
    "    \n",
    "    #xmat has rows with authorities and columns as xvariables\n",
    "    for j in range(len(xvar)):\n",
    "        for i in range(len(authoritynames)):\n",
    "            #only take 2020\n",
    "            xmat[i,j] = std_values[authoritynames[i]].iloc[xvar[j],yeari]\n",
    "            \n",
    "    \n",
    "    return yvec, xmat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013605d",
   "metadata": {},
   "source": [
    "#### For higher income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ed10f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>highincome_coefficient</th>\n",
       "      <th>highincome_linreg_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>5.437022e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>-0.462088</td>\n",
       "      <td>2.834678e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.394803</td>\n",
       "      <td>2.449819e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>-0.795424</td>\n",
       "      <td>6.379808e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>-1.158091</td>\n",
       "      <td>9.912192e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>-0.960561</td>\n",
       "      <td>5.835767e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.146554</td>\n",
       "      <td>2.065198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>-0.053081</td>\n",
       "      <td>6.327081e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>9.347575e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>-0.141362</td>\n",
       "      <td>1.758075e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>-0.127940</td>\n",
       "      <td>1.059846e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.214148</td>\n",
       "      <td>4.799535e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>8.622407e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  highincome_coefficient  highincome_linreg_p_value\n",
       "0   2008                0.019958               5.437022e-01\n",
       "1   2009               -0.462088               2.834678e-10\n",
       "2   2010               -0.394803               2.449819e-06\n",
       "3   2011               -0.795424               6.379808e-22\n",
       "4   2012               -1.158091               9.912192e-29\n",
       "5   2013               -0.960561               5.835767e-11\n",
       "6   2014               -0.146554               2.065198e-01\n",
       "7   2015               -0.053081               6.327081e-01\n",
       "8   2016                0.008960               9.347575e-01\n",
       "9   2017               -0.141362               1.758075e-01\n",
       "10  2018               -0.127940               1.059846e-01\n",
       "11  2019               -0.214148               4.799535e-06\n",
       "12  2020               -0.007985               8.622407e-01"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize a dataframe with 13 years of pvalue\n",
    "linreg_twovarhighincomedf = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),3]),columns=['year','highincome_coefficient','highincome_linreg_p_value'])\n",
    "linreg_twovarhighincomedf.iloc[:,0] = list(range(2008,2021))\n",
    "#iterate over years from year 2008 to 2020: (2008 corresponds to 4th column of stdvalue and 2020 corresponds to 17th column of stdvalue)\n",
    "for i in range(4,17):    \n",
    "    #compute all regression using initialized function for xvec and yvec \n",
    "    yvec,xvec = Initializationforveclinreghighincomelowincome(i,highincome=True)\n",
    "    resultsvec = sm.OLS(yvec,xvec).fit()\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    linreg_twovarhighincomedf.iloc[i-4,1] = resultsvec.params[-2]\n",
    "    linreg_twovarhighincomedf.iloc[i-4,2] = resultsvec.pvalues[-2]\n",
    "\n",
    "#show the result\n",
    "linreg_twovarhighincomedf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d6d3a",
   "metadata": {},
   "source": [
    "#### For lower income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf96bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>lowincome_coefficient</th>\n",
       "      <th>lowincome_linreg_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.060821</td>\n",
       "      <td>1.749854e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>-0.283477</td>\n",
       "      <td>1.559257e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.388367</td>\n",
       "      <td>7.180368e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>-0.810640</td>\n",
       "      <td>1.102718e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>-0.905907</td>\n",
       "      <td>4.374758e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>-0.908127</td>\n",
       "      <td>2.357246e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.187748</td>\n",
       "      <td>2.075187e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.049636</td>\n",
       "      <td>5.397839e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.087913</td>\n",
       "      <td>2.797936e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>-0.120061</td>\n",
       "      <td>1.973854e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>-0.243348</td>\n",
       "      <td>2.195901e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.117408</td>\n",
       "      <td>1.940731e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.080958</td>\n",
       "      <td>1.061517e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  lowincome_coefficient  lowincome_linreg_p_value\n",
       "0   2008               0.060821              1.749854e-01\n",
       "1   2009              -0.283477              1.559257e-04\n",
       "2   2010              -0.388367              7.180368e-06\n",
       "3   2011              -0.810640              1.102718e-25\n",
       "4   2012              -0.905907              4.374758e-17\n",
       "5   2013              -0.908127              2.357246e-13\n",
       "6   2014              -0.187748              2.075187e-02\n",
       "7   2015               0.049636              5.397839e-01\n",
       "8   2016               0.087913              2.797936e-01\n",
       "9   2017              -0.120061              1.973854e-01\n",
       "10  2018              -0.243348              2.195901e-03\n",
       "11  2019              -0.117408              1.940731e-02\n",
       "12  2020              -0.080958              1.061517e-01"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize a dataframe with 13 years of pvalue\n",
    "linreg_twovarlowerincomedf = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),3]),columns=['year','lowincome_coefficient','lowincome_linreg_p_value'])\n",
    "linreg_twovarlowerincomedf.iloc[:,0] = list(range(2008,2021))\n",
    "#iterate over years from year 2008 to 2020: (2008 corresponds to 4th column of stdvalue and 2020 corresponds to 17th column of stdvalue)\n",
    "for i in range(4,17):    \n",
    "    #compute all regression using initialized function for xvec and yvec \n",
    "    yvec,xvec = Initializationforveclinreghighincomelowincome(i,lowincome=True)\n",
    "    resultsvec = sm.OLS(yvec,xvec).fit()\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    linreg_twovarlowerincomedf.iloc[i-4,1] = resultsvec.params[-2]\n",
    "    linreg_twovarlowerincomedf.iloc[i-4,2] = resultsvec.pvalues[-2]\n",
    "\n",
    "\n",
    "#show the result\n",
    "linreg_twovarlowerincomedf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a69b8a",
   "metadata": {},
   "source": [
    "### Elasticity for income\n",
    "\n",
    "The elasticity can be calculated by regression coefficient. The derivation is simple (according to online source): \n",
    "$$\\text{Elasticity}=\\frac{\\text{Percentage change in X}}{\\text{Percentage change in Y}}=\\frac{\\frac{dY}{Y}}{\\frac{dX}{X}}=\\frac{dY}{dX}\\frac{X}{Y}=b\\frac{X}{Y}$$\n",
    "where X is the earnings data and Y is the unemployment data. Since $\\frac{dY}{dX}$ is the coefficient in the regression model, we can call it b which is estimated by maximum likelihood estimate. The value for X and Y, however, is not a fixed value across all authorities. TJ Valentine gives a solution by taking mean value of X and Y. Thus the above formula becomes:\n",
    "$$\\text{Elasticity}=b\\frac{\\bar X}{\\bar Y}$$\n",
    "where $\\bar X$ is the mean value of X and $\\bar Y$ is the mean value of Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c4942",
   "metadata": {},
   "source": [
    "#### Elastictity For higher income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2902b7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value for higher quantile elasticity: 0.04159807380469595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Elasticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.080167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.072234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.058778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.079609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.073921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.019771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.017583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.024145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>-0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.039348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.039029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.069561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.004650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Elasticity\n",
       "0   2008    0.080167\n",
       "1   2009    0.072234\n",
       "2   2010    0.058778\n",
       "3   2011    0.079609\n",
       "4   2012    0.073921\n",
       "5   2013    0.019771\n",
       "6   2014   -0.017583\n",
       "7   2015    0.024145\n",
       "8   2016   -0.002855\n",
       "9   2017    0.039348\n",
       "10  2018    0.039029\n",
       "11  2019    0.069561\n",
       "12  2020    0.004650"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticity_table_higher = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),2]),columns=['Year','Elasticity'])\n",
    "elasticity_table_higher.iloc[:,0] = list(range(2008,2021))\n",
    "for i in range(4,17):    \n",
    "    #compute all regression using initialized function for xvec and yvec \n",
    "    yvec,xvec = Initializationforveclinreghighincomelowincome(i,highincome=True)\n",
    "    elasticity_table_higher.iloc[i-4,1] = linreg_twovarhighincomedf.iloc[i-4,1]*np.mean(xvec)/np.mean(yvec)\n",
    "print(f'mean value for higher quantile elasticity: {np.mean(elasticity_table_higher.iloc[:,1])}')\n",
    "elasticity_table_higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1eb33",
   "metadata": {},
   "source": [
    "#### Elastictity For lower income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6809991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value for lower quantile elasticity: 0.04799295310390831\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Elasticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.244304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.044314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.057819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.081132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.057824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.018692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.022525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>-0.022578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>-0.028009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.033418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.074235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.038137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.047146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Elasticity\n",
       "0   2008    0.244304\n",
       "1   2009    0.044314\n",
       "2   2010    0.057819\n",
       "3   2011    0.081132\n",
       "4   2012    0.057824\n",
       "5   2013    0.018692\n",
       "6   2014   -0.022525\n",
       "7   2015   -0.022578\n",
       "8   2016   -0.028009\n",
       "9   2017    0.033418\n",
       "10  2018    0.074235\n",
       "11  2019    0.038137\n",
       "12  2020    0.047146"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticity_table_lower = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),2]),columns=['Year','Elasticity'])\n",
    "elasticity_table_lower.iloc[:,0] = list(range(2008,2021))\n",
    "for i in range(4,17):    \n",
    "    #compute all regression using initialized function for xvec and yvec \n",
    "    yvec,xvec = Initializationforveclinreghighincomelowincome(i,highincome=True)\n",
    "    elasticity_table_lower.iloc[i-4,1] = linreg_twovarlowerincomedf.iloc[i-4,1]*np.mean(xvec)/np.mean(yvec)\n",
    "print(f'mean value for lower quantile elasticity: {np.mean(elasticity_table_lower.iloc[:,1])}')\n",
    "elasticity_table_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957075e",
   "metadata": {},
   "source": [
    "#### Elastictity For median income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98ccd233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value for median quantile elasticity: 0.23263207062426722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Elasticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>-0.044186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.281367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.332083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.548133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.755570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.518894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.190248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.014201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>-0.053840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.058861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.192692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.145548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.084647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Elasticity\n",
       "0   2008   -0.044186\n",
       "1   2009    0.281367\n",
       "2   2010    0.332083\n",
       "3   2011    0.548133\n",
       "4   2012    0.755570\n",
       "5   2013    0.518894\n",
       "6   2014    0.190248\n",
       "7   2015    0.014201\n",
       "8   2016   -0.053840\n",
       "9   2017    0.058861\n",
       "10  2018    0.192692\n",
       "11  2019    0.145548\n",
       "12  2020    0.084647"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticity_table_median = pd.DataFrame(data = np.zeros([len(list(range(2008,2021))),2]),columns=['Year','Elasticity'])\n",
    "elasticity_table_median.iloc[:,0] = list(range(2008,2021))\n",
    "for i in range(4,17):    \n",
    "    #compute elastictiy using coefficient calculated for median income \n",
    "    elasticity_table_median.iloc[i-4,1] = linreg_twovarincomedf.iloc[i-4,1]*np.mean(xvec)/np.mean(yvec)\n",
    "print(f'mean value for median quantile elasticity: {np.mean(elasticity_table_median.iloc[:,1])}')\n",
    "elasticity_table_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c08ce1",
   "metadata": {},
   "source": [
    "# Linear regression with time lag of 2 years\n",
    "\n",
    "As suggested in paper by Ruhm, Christopher J, wage and employment alteration begin with a lag of two calendar years. And also by our result in distance correlation where some of the correlation with 2 year lags is significant, which has higher number than other lags. Therefore, we choose lag with 2 years as our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28fea381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function for xmatrix and ymatrix with different year.\n",
    "def Initializationforveclinregdiffyear(yeari,yearj):\n",
    "    #first, compute yvec corresponding unemployment for year i. Initialize it\n",
    "    yvec = np.zeros([len(authoritynames),1])\n",
    "    #Plug in the values for yvec\n",
    "    for j in range(len(authoritynames)):\n",
    "        #only take yeari data for unemployment\n",
    "        yvec[j] = std_values[authoritynames[j]].iloc[4,yeari]\n",
    "        \n",
    "    #now, compute xvec corresponding earnings for yeari. Initialize it. Note xvec is 205*2 matrix, in which the first column is all ones,\n",
    "    #corresponding to interception. \n",
    "    xmat = np.zeros([len(authoritynames),len(xvariable)+1])\n",
    "    #Plug in the values for xvec, here the first column all equal to one\n",
    "    xmat[:,0] = 1\n",
    "    \n",
    "    #xmat has rows with authorities and columns as xvariables\n",
    "    for j in range(len(xvariable)):\n",
    "        for i in range(len(authoritynames)):\n",
    "            #only take 2020\n",
    "            xmat[i,j] = std_values[authoritynames[i]].iloc[xvariable[j],yeari]\n",
    "    for i in range(len(authoritynames)):\n",
    "        xmat[i,-1] = std_values[authoritynames[i]].iloc[-6,yearj]\n",
    "            \n",
    "    \n",
    "    return yvec, xmat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21837ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_unemployment</th>\n",
       "      <th>year_earning</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>linreg_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>-0.106298</td>\n",
       "      <td>8.809424e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>-0.492653</td>\n",
       "      <td>1.527897e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>-0.845833</td>\n",
       "      <td>1.196589e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>-0.740442</td>\n",
       "      <td>1.457299e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-0.294277</td>\n",
       "      <td>3.575178e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>8.672481e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.198190</td>\n",
       "      <td>1.128585e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>8.312723e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.078577</td>\n",
       "      <td>4.556035e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>-0.272375</td>\n",
       "      <td>6.214583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>-0.114544</td>\n",
       "      <td>2.936372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>4.215690e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>-0.306362</td>\n",
       "      <td>1.374630e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-0.164645</td>\n",
       "      <td>1.304658e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>-0.670935</td>\n",
       "      <td>3.570372e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>-0.665688</td>\n",
       "      <td>3.265561e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>-0.094611</td>\n",
       "      <td>5.794747e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.401409</td>\n",
       "      <td>2.481736e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>-0.002996</td>\n",
       "      <td>9.734657e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>-0.248243</td>\n",
       "      <td>3.425503e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>-0.110004</td>\n",
       "      <td>8.899304e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>-0.124522</td>\n",
       "      <td>2.416078e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_unemployment  year_earning  coefficient  linreg_p_value\n",
       "0              2010.0        2008.0    -0.106298    8.809424e-02\n",
       "1              2011.0        2009.0    -0.492653    1.527897e-07\n",
       "2              2012.0        2010.0    -0.845833    1.196589e-18\n",
       "3              2013.0        2011.0    -0.740442    1.457299e-17\n",
       "4              2014.0        2012.0    -0.294277    3.575178e-04\n",
       "5              2015.0        2013.0     0.015240    8.672481e-01\n",
       "6              2016.0        2014.0     0.198190    1.128585e-01\n",
       "7              2017.0        2015.0     0.026878    8.312723e-01\n",
       "8              2018.0        2016.0    -0.078577    4.556035e-01\n",
       "9              2019.0        2017.0    -0.272375    6.214583e-03\n",
       "10             2020.0        2018.0    -0.114544    2.936372e-01\n",
       "11             2008.0        2010.0     0.067211    4.215690e-01\n",
       "12             2009.0        2011.0    -0.306362    1.374630e-04\n",
       "13             2010.0        2012.0    -0.164645    1.304658e-01\n",
       "14             2011.0        2013.0    -0.670935    3.570372e-08\n",
       "15             2012.0        2014.0    -0.665688    3.265561e-05\n",
       "16             2013.0        2015.0    -0.094611    5.794747e-01\n",
       "17             2014.0        2016.0     0.401409    2.481736e-05\n",
       "18             2015.0        2017.0    -0.002996    9.734657e-01\n",
       "19             2016.0        2018.0    -0.248243    3.425503e-03\n",
       "20             2017.0        2019.0    -0.110004    8.899304e-02\n",
       "21             2018.0        2020.0    -0.124522    2.416078e-02"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize a dataframe with 11*2 years of pvalue\n",
    "linreg_twovardiffyeardf = pd.DataFrame(data = np.zeros([2*(len(list(range(2008,2021)))-2),4]),columns=['year_unemployment','year_earning','coefficient','linreg_p_value'])\n",
    "\n",
    "#iterate over years from year 2008 to 2018: (2008 corresponds to 4th column of stdvalue and 2018 corresponds to 15th column of stdvalue)\n",
    "#unemployment at year i+2 and earning at year i (lag by 2)\n",
    "for i in range(4,15):    \n",
    "    #compute all regression using initialized function for xvec and yvec but yvec with year i and yvec with year i+2\n",
    "    yvec,xvec = Initializationforveclinregdiffyear(i+2,i)\n",
    "    resultsvec = sm.OLS(yvec,xvec).fit()\n",
    "    #get the pvalue for coefficient between unemployment year i+2 and earning year i \n",
    "    linreg_twovardiffyeardf.iloc[i-4,3] = resultsvec.pvalues[-1]\n",
    "    linreg_twovardiffyeardf.iloc[i-4,0] = 2004+i+2\n",
    "    linreg_twovardiffyeardf.iloc[i-4,1] = 2004+i\n",
    "    linreg_twovardiffyeardf.iloc[i-4,2] = resultsvec.params[-1]\n",
    "\n",
    "#iterate over years from year 2008 to 2018: (2008 corresponds to 4th column of stdvalue and 2018 corresponds to 15th column of stdvalue) \n",
    "#unemployment at year i and earning at year i+2 (lag by 2)\n",
    "for i in range(4,15):\n",
    "    #compute all regression using initialized function for xvec and yvec but yvec with year i and yvec with year i+2\n",
    "    yvec,xvec = Initializationforveclinregdiffyear(i,i+2)\n",
    "    resultsvec = sm.OLS(yvec,xvec).fit()\n",
    "    #get the pvalue for coefficient between unemployment year i and earning year i+2, now the indices will be computed start from i-4+11 = i+7\n",
    "    linreg_twovardiffyeardf.iloc[i+7,3] = resultsvec.pvalues[-1]\n",
    "    linreg_twovardiffyeardf.iloc[i+7,0] = 2004+i\n",
    "    linreg_twovardiffyeardf.iloc[i+7,1] = 2004+i+2\n",
    "    linreg_twovardiffyeardf.iloc[i+7,2] = resultsvec.params[-1]\n",
    "    \n",
    "\n",
    "#show the result\n",
    "linreg_twovardiffyeardf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e538a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca279f26",
   "metadata": {},
   "source": [
    "# Regression with respect to Time Series for different authority with unemployment and wages only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f174b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here Initialize the xmatrix and ymatrix for each authority\n",
    "def Initialization_for_authority_i(i):\n",
    "    yvec = np.zeros([13,1])\n",
    "    yvec[:,0] = std_values[authoritynames[i]].iloc[4,4:]\n",
    "\n",
    "    xmat = np.zeros([13,2])\n",
    "    #initialize interception as a column of one\n",
    "    xmat[:,0] = 1\n",
    "    xmat[:,1] = std_values[authoritynames[i]].iloc[-6,4:]\n",
    "    return yvec, xmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b578bf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorityname</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Darlington</td>\n",
       "      <td>-0.41361</td>\n",
       "      <td>0.073276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>County Durham</td>\n",
       "      <td>-0.539208</td>\n",
       "      <td>0.043058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>-0.584376</td>\n",
       "      <td>0.026438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>-0.686372</td>\n",
       "      <td>0.013837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Northumberland</td>\n",
       "      <td>-0.137464</td>\n",
       "      <td>0.604999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>South Ayrshire</td>\n",
       "      <td>-0.514383</td>\n",
       "      <td>0.092108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>South Lanarkshire</td>\n",
       "      <td>-0.409121</td>\n",
       "      <td>0.031326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Stirling</td>\n",
       "      <td>-0.516012</td>\n",
       "      <td>0.027255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>West Dunbartonshire</td>\n",
       "      <td>-0.901448</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>West Lothian</td>\n",
       "      <td>-0.621677</td>\n",
       "      <td>0.048135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           authorityname coefficient   p-value\n",
       "0             Darlington    -0.41361  0.073276\n",
       "1          County Durham   -0.539208  0.043058\n",
       "2             Hartlepool   -0.584376  0.026438\n",
       "3          Middlesbrough   -0.686372  0.013837\n",
       "4         Northumberland   -0.137464  0.604999\n",
       "..                   ...         ...       ...\n",
       "200       South Ayrshire   -0.514383  0.092108\n",
       "201    South Lanarkshire   -0.409121  0.031326\n",
       "202             Stirling   -0.516012  0.027255\n",
       "203  West Dunbartonshire   -0.901448  0.000974\n",
       "204         West Lothian   -0.621677  0.048135\n",
       "\n",
       "[205 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authority_pvalue = pd.DataFrame(index=range(205), columns=['authorityname','coefficient','p-value'])\n",
    "for i in range(205):\n",
    "    #compute all regression using initialized function for xmat and yvec with respect to authority i\n",
    "    yvec,xmat = Initialization_for_authority_i(i)\n",
    "    resultsvec = sm.OLS(yvec,xmat).fit()\n",
    "    authority_pvalue.iloc[i,2] = resultsvec.pvalues[1]\n",
    "    authority_pvalue.iloc[i,1] = resultsvec.params[1]\n",
    "    authority_pvalue.iloc[i,0] = authoritynames[i]\n",
    "authority_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc3b05",
   "metadata": {},
   "source": [
    "For visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2294c945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJoAAAEDCAYAAADN4R0oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABNlklEQVR4nO29d3ikV3n3/zlPmV7Ve1tt73297sa4Aaa8IRgIxhhCDeUlBZK8SQh5k5A3EMqPFlOCHYIJxaEYV3DBZdfbe5N21Xud3p/z+2NGWvW22l1JO5/r0qXRU2bOzHx16n2+t5BSkiXL5Ua52gXIcm2QFVqWK0JWaFmuCFmhZbkiZIWW5YqQFVqWK8JVFZoQ4vtCiG4hxIkZXv+HQohTQoiTQogfXe7yZZk/xNWcRxNC3AQEgUeklOumuXY58BPgNinlgBCiQErZfSXKmeXSuao1mpTy90D/yGNCiGVCiKeEEAeFEC8JIVZlTv0x8A0p5UDm3qzIFhELsY/2EPBxKeVW4M+Ab2aOrwBWCCFeEULsFULcddVKmGXWaFe7ACMRQjiA3cBPhRBDh82Z3xqwHLgFKANeEkKsk1IOXuFiZpkDC0popGvYQSnlpgnOtQJ7pZQJoEEIcZa08PZfwfJlmSMLqumUUvpJi+jtACLNxszpXwC3Zo7nkW5KL1yNcmaZPVd7euNRYA+wUgjRKoR4P/Bu4P1CiKPASeDNmcufBvqEEKeA54E/l1L2XY1yZ5k9V3V6I8u1w4JqOrMsXa7aYCAvL09WVVVdrZfPchk4ePBgr5Qyf6JzV01oVVVVHDhw4Gq9fJbLgBCiabJz2aYzyxUhK7QsV4Ss0LJcERbaysCSJZFI0NraSjQavdpFuWQsFgtlZWXouj7je7JCu0K0trbidDqpqqpixDruokNKSV9fH62trVRXV8/4vmzTeYWIRqPk5uYuapEBCCHIzc2ddc2cFdoVZLGLbIi5vI9s07lA8UcTPHm8g25/jAKXmbvXF+OyzLxPtNCYtkabLq5fCPFuIcSxzM+rI6ItssyRrz9Xx65/+h2f+flxvvTsOT7z8+Ps+qff8fXn6gCIJZMEE0nmsk791FNPsXLlSmpra/nCF74w7ryUkk984hPU1tayYcMGDh06dMnvB2bWdP4AmCqatQG4WUq5AfgH0hGyWebI15+r44vPnCMcT406Ho6n+OIz5/j6c3X0Jw26E6lJnmFyUqkUH/vYx3jyySc5deoUjz76KKdOnRp1zZNPPkldXR11dXU89NBDfOQjH7mk9zPEtEKbKK5/zPlXh+L4gb2ko1+zzAF/NME3Xzg/5TXfeOE8/ZEEDlWZdV9p37591NbWUlNTg8lk4r777uOXv/zlqGt++ctfcv/99yOEYNeuXQwODtLR0THr9zKW+R4MvB94cp6f85rhyeMd42qysUTiKV4904NDnf1X19bWRnl5+fDfZWVltLW1zfqauTBvgwEhxK2khXbDFNd8EPggQEVFxXy99JKh2x+b0XW+YIyIYWCRCsosarWJ+nRja8WZXDMX5qVGE0JsAL4LvHmqqFcp5UNSym1Sym35+RNGk1zTFLjM018EFLssKMBsv/6ysjJaWlqG/25tbaWkpGTW18yFSxaaEKICeAx4j5Ty3CWX6Brm7vXF2EzqlNdYdJV7N5bgNemzrmm2b99OXV0dDQ0NxONxfvzjH3PvvfeOuubee+/lkUceQUrJ3r17cbvdFBcXz/q9jGXapjMT138LkCeEaAX+DtABpJTfBv4WyAW+mXnjSSnltksu2TWIy6Lz0VuW8cVnJv9//cjNNTgt+nATNxuxaZrG17/+de68805SqRQPPvgga9eu5dvf/jYAH/7wh7nnnnt44oknqK2txWaz8R//8R+X9qYyXLU9A9u2bZPXUuDj6dOnWb169Yyu/fpzdXzzhfOjBgYWXeX+G6v45G3LsaoKSEkskcBqnllzO99M9H6EEAcnq2SyKwMLkI/esoz7dpTz29PddPqi2G06m1bm4bboxFMpwimDXF29aiKbC1mhLUAURcFm0bhpXSFxwyCOIJIySEqJTdMwKWLRrZtmhbZAURD0JdNNpyrSP15NRROLT2SQjd5YsFg0lVqrCbuqkKOp2FWFFBA3jKtdtDmRFdoCQUpJfzwx6phV0ygzabiFxKyka7GBZApjEW76zjadCwQhBF794tfhT6Z4vHuQrniCPE1lq9tOucWEQ1OzTWeWS2NIQF9p7GTTqyf59NkW/qWhkz+va+MNh+r4Vkv3JYnswQcfpKCggHXrJjbXvFwhQpAV2oLjK42dfKGhk3BqdF8sYkj+rambrzR2zvm5H3jgAZ566qlJz1+uECHICm1B4U+m+Frz1I6pX2vuJpCcfSwawE033UROTs6k5y9XiBBkhbageLx7cFxNNpZwyuDXPYOX5fUvV4gQZIW2oOgaM+qcjO7YzK6bLZcrRAiyQltQFJpmtvmkwHx5NqlcrhAhyAptQfHGAg+2aSJnbarCm/I9l+X1L1eIEGTn0RYULk3lExUFfKFh8pHlJyoKcGpTx6xNxjvf+U5eeOEFent7KSsr4+///u9JJNLN8OUMEYKs0BYcn6oqAtKjy5EDA5uq8ImKguHzc+HRRx+d8rwQgm984xtzfv6pyAptAfKpqiLeX5bPT9t78RuSArPOm/I9c67JFgJZoS1QnJrKgxWFV7sY80Z2MHAFmWj6YDG6os+lzFmhXSFMZjNtHV0YI8J8DCmJTLOPc6ExZFtlsVhmdV+26bxC/OZ8jO35UQK+9Kb+RMpAESAQKMriisYYMuKbDVmhXSHuWVdEbyiB2WXBZlL5z9dauHF5PuuKnTispqtdvMvONS+0eNLApF3eHkTbYIRAAjaWe/jN8S6K3RY+flstuqqiLrLabK5ck320SCQy/Fhw+Trjp9sG+OzPj/HCqTb++YnTnGztp9htoTrXytGmPq4RjQHXqNCsVuvwY30Oc1MzHXX9YE8LP97fwl//6ixv2ljM8iIP1fl2BqMGext9pIzFN+KcK/NhxCeEEF8TQtRnzPi2zH8xFw5SyhlHNAyE06YtXpvOyiIXz5zsoq47xJoSFx+4vhJtDo5Ai5X5MOK7m3SC1uWknYK+denFWrjMJmzGbtZYlm8nnjT4i58d40x3EJMCXb4Iduvi2fw7H0w7GJBS/l4IUTXFJW8GHpHp9mSvEMIjhCiWUs5PaOYipb47SIXHwo3L8+jwxbh1ZQHv/M5eun1R3nd9JYVu6/RPsoSYj1FnKdAy4u/WzLFxQruW/NGiiRTf+n0j79pZwcduWYbTqvGPb13HxjIPBY7Fa3o8V+ZDaBO1JRP2cqWUD5HxuN22bduS7gmvK3Xzrp0VNPSGONjcTyhmEIonKc+xXe2iXRXmQ2itQPmIv8uA9nl43kXPZ+9eRU8ghteicrTNTzB+7U5bzsew51fA/ZnR5y7Ad633z4aw6CrlOTaSEnbV5HLL8ryrXaSrxnwY8T0B3APUA2HgfZersFea5892E4nEuKE2F5djZk1eypAkkilOdQb4n0NtYKRYXerh9tWF5DuvrZHmSGYy6nznNOcl8LF5K9Fl5ODx02xdPzMzvEQyxRefPsvJdj/3rCvivTvLONPppzTXyXU1udgtOr3BGHvre6jKc6Ar8Ny5Xr782zqW5TvIsemc7gzQH4pjN3Vw17riRWllMF9cE50GKSWPvlrPd/Z08ovqKtyO6acW/vS/D3Gy3Q/AK+f7UBTBkZZBEimDN60vos0X4+X6XgLR5Lh7T3f4R/39zp0V5NiX/sL5VCx5ofmjCT77s6M8caILgEDcwD2D+yrtBm6rji+S3rxR1x2kdSDCqiIn331l0tThE2LVVQxDLrpwoPlkUQotHo8jJZjNk9cSPQM+fra/iSfODHK8PQBAdZ6dAtf0AXu/P3yWk71xgrF0beWLJIYFd6YzMOvyvlzfy6dfv2LW9y0lFqXQpJQkk8kJhRYKhThe18RfPNNJc39k1Lk/2FyMaQaL6IMxg+fq/dNeN1PetaPimu6fwSIVmtlsxjyBUfCvj7bT3TdIfbcf85gYsz/aXsJd60to6g1Qmeec8HlDkRiJZIoiU5wyr5XWgciE180Ui67wwHWVvH1b+fQXL3EWpdAmom/Qz9d+e45QIkWRQxsVUOiyaGyp8PDQi+f5u3vXTvocvzzazuPHOrjQE0IoChtLXRxtm1vNdseaQv7prevIc84utn6psmSEdqChl7qeEAADIZVIJs2gImBTqYO3bK3ibdunbr7etqWMR/e30hmIA9Dhm1065yGK3Ra+9IcbcS7iRK7zzZIJiCr12ri+NheLrhBJpFAE5Nh1Sj1WhDSmHfH5wjGCsRQbii5tLbIm384PHtiWFdkYFn2NZhgSw0hxqt1HY2+YaCK9nW11sYtTHX68NhOGMv2X3tYf5lM/OUYsOXfX6zvWFPLld2zCbl70H+u8s+BqNCklwfDMmyxFEWiaxu1rinj/rlI2lroAUBWBTVcZCCd46D1bp30eLeHjU69bRvNAeE7l/tyb1vDv79maFdkkLKhPpb1nkHBSUlvsnfW9im6hwG1l17JckoYkx27igTetZPuytK3AZBOmhiGJJ1PkeHPZ7FF49I938ic/OkxvMD7uWl0VJA3JyC0DXpvOp25fwbt2ZqcwpmJBCa0k30N8hq6HQwxtFDneNshTp3t59lQXa0tcvHdrPresr0IIQTI1cR+tuS/IgcZ+Xj7fzx9uLeOJE53UdQUp89omFFoiJbHqKikpiScNVEXwrp0VvHd31Zze77XEghIagGmGrodDBCIxmvojaEaS5892c/OKPP72jWso9dqGa5iJNoFIKXn9l1/iL+5cwdGWQV4420MwlmR1sYvW/jD5TjM9gfEZgSOJFKuLXbgsGoUuCxvLPCSTBh3+6DUb1DgTFpzQpiMWi49aEUhJQU8gTqk5wUPv3syWylysI/pJqUxtNrZZMyQIAc+f7aU7EBteHD/aMjhtGYYWzVcWOukORHlkTyPvu746K7QpWHRCGxLZT189i9DN9IeTnLjQxnt3lrJzRR7amCUmRRGc7QwgBKwscg0fT6YMPvemNfzr0+cmjMCYCWe7Apg0hf+1pYzbVhXM/U1dAyw6oQGEo3EePtDFyY4AUsItpYJ+aR8nMkg3dQ/+YD9VuXa+995tw7WdP5rkb395isQcknjZTSrrSt18+OZlHGv18cD1VaNqzNMdfn70WhNWk8YHb6ohz2FGSsnZzgBlXit2szbqesMwSBrpsros2pIcVCwqoUkpGfCHUHWdHzy4g68+e5bfnu6hT5q4vjZ/1LUvnO1GMVLctLoYp0Xn1Qt9PHakjXfvrCQai+O16bznukq+93LDrMpgN6m8ZXMpTxzv4LsvX+DP71yF26oTS6T4z73p8KGH9zTSklnQf/jVRm5ZmY8/kmTPhT62Vnho90VZV+LCbVGIJC7WjKc6AtyzvoivvGPzZfcDudIsKqEJIfA40518IQQ7q7zEgwPkO3VsI/plnb4o5V4rn3/8NKW5DmKZTCNdviiRWIIznUH+50g7xW4Lb9tcSn1PkGOtvhmVYW2pmx/ta0YRgtevLuS1C3009YV4dF8zR1oGhyeMh4glDZ4+2TX8d0qml7YmW9564ngnufZT/MNbJs7XtFhZVEKDdHZeSNduX/ztecrskg/eONoL//97ro5cm8bL9b287Vt7yHWk+3U2s8axlgE2lHl4qa6Xht4QuQ4TvvDMp1SOtQ4iJXzq9uXomsLnHz/FkIXGmsxqxGTk2Ew094UmHdEO8fzZqdP0LEYWbf3cNhhhTbELrT1CYf7oZjNlSL79UiMui4YvkuBCTwiTqrAs38GrDYNYLSY2lKXjbPuCcZIzNFtRBGwq9/CWTSUcbhnkr//nBCNvdVgm/79dU+xEIilyW6d1EWodiNDSH5pRmRYLi65GG8KqqzxxopMPbc/FYR89rfDRW2ppHYjwkZtr+NyvT1HXHUQiudATpLk/vcRUmWMjz2GiNt+BISXne0L0hcZP0o7EkLD3Qv+k5xMpg03lHnRVcKLdP842dCCcYGAGtafHqmMSi8tydDoWrdBeONsDgI/xc1cVuTb+8/076AvF8dpM5DnM9AZjnGz3s7HMTftAmDduLGFTuYufHmzjUPPgtCKbCYebB4cfryt1cWJELJtFn7k91l/dUU2h1zX9hYuIRSu0M51+yj1mPnpzzYTnhRDkOcyYNAV/Jt7/6ZOdRBMpKnNtFHusHG4ewKJruCz6rJrQ6dhc7uZwy+jBxUwsqjRF8NGbqvjD65bPSzkWEotWaF67CbOuTmuK989vW8eDPzhAY18IKeFo6yB7LvQRiCYp91rRVAVFQKHLQtvgpYVuD6GIi6LaUOrGYlKHxT4VOXYTH7t95byUYaExI6EJIe4CvgqowHellF8Yc94N/BCoyDznF6WU85dIaAK2l7s43mInMI19enmOna+/czNHW310+qNsr/Lyj785Ta7DzG0rc/m7X5+Z97L5oulmeFWRg2Nt00+bbK/ykjQkr19TiHkRZ0eZipk4PqrAN0gb7q0B3imEWDPmso8Bp6SUG0nbJ3xJCHHZdszGk+kI2g/srmBtycS7NGPJ1PC0xcpiF3+4vZyP3rKMF8710B2I8fHbaukMJPjgjdUUuSxY9PkZgNfk2QHB2hInZzqDM7onZUgONw+ypnhp9ctGMpMabQdQL6W8ACCE+DFp871TI66RgFOk104cQD8wtwXEaUgkU3z8R4dY70nx3ts3T7pc09IfRjFS/PvvOzFrKp+8fTmqInjhTA9ffscmTrX7+MErjUSTKUyqckmRtUNcV5PDQDiBlBLHDHNqLi9wEIql2FrhoXWOQZeLgZkIbSKjvZ1jrvk6aVehdsAJvENKOe6bmw8jvuNtPlYX2vnAbSuw6BMXP5lMUlvgJBxPcrR1EF8kwSdvX44Qgsc/fj2RRIofvNrIh2+u4ScHWunyz20Tykg2lrnZ3zgw6wFFXXdweH3zTRvmJwnrQmQmQpuJ0d6dwBHgNmAZ8KwQ4iUp5ahp8vkw4iuwCd66pXRSkQFoWvqczaTx5Xdsotsf42BTP6uKXNjNGk8fb+PZU128Ut9LPGnMy2hTV5Upn0cCDrtOKDR+UOCPJvnHt67DbVu6/hwz6ZjMxGjvfcBjMk090ACsmp8iXuRYcy92s4nK/Jm4Z6QpcFpYW+Li+TPd6KpCKmVQ3x3k1hV5GFLOXWSZf781GwtYv60IUWilqsZDTu5FAxmTSUECq99Ug/MNFSRvLmLLbRPX5G9cv3RrM5hZjbYfWC6EqAbagPuAd425phl4HfCSEKIQWAlcmM+CApTnOvDYZu8xdr47wJ/deVH3N60s4ERHEDGisjZp6SWqYDRB22CEqfSXn29D7CrAJgRthkFXItMd9drZaM6hrCOC2aZx0iFYrmgcjF9c13xVh21bCjlx6OJCu9uqYzMvzdHmEDPxR0sKIf4EeJr09Mb3pZQnhRAfzpz/NvAPwA+EEMdJ/69/RkrZO9+F9drntuu7ttDF4aZ+/NEE/kiS420D7GscGN5kDOlUPac7/Gyv8tLui8KY+Tm7QyeVlKx4XQX7kjGYZG/D0VgMchQ2Osz0ByP0M376xeQc3UT+9T2r0Zd4zoEZzaNJKZ8g7ew48ti3RzxuB+6Y36JdGv5gkM7+ACsqimno9vPu7+0jnJlzc1q0cd4ckB41nu8JTZjRpOaWcppJsS8xedTFSKZqkM87FbbeWsGZve186IYa3r5tdpniFiOLdmVgKroDUT78yGH+zxvTPhvFbgvff2A7BQ6dH+9rpqEvQoc/Sp7dRGcgxmA4wR/tqmB1sYtHXm0kljQIRBMYMi2YHK+F00aCYGrmUyCWKWqorkSSuE3lgXet5xPLl3bfbIglJ7T2/iA/OdDMg9dVsKUyh/M9Qb749BmePNHFh26q5qeH2kmmJIGM95lVV/nLu1exodTNR350CLflovkeQGGBndydhXTEZ1aTDbHPF2KH20Z9KEZ/cnzzGUilWOu+djazLAmh9fsCfH9PC7qqcsMyD598/WqEEBiGwel2H89nIj2++3Ij//fNa/nyb+sACMSSvG1LKburnHzo0aO4LTqDkQS6ml6Q11RBsd2E71g/OetcEwpmKvb5wuxy29nrGx9bJhDc4HVc+ptfJCwJoSm6iSOtAf75resoz7UD6R3o/lCYLeVu/vT2Wp462YWB4OE9Tdy4PI8tlR76AnGWFzrZ2+inzGPjaOsg60rdaIpgf2M/hoQ2X5SyN1QRjCcoNGnk6hqnQjOf4E1MsOhvVgR/UV2MZ4q5wKXGkninHpuZh9+3DVW9OEUgpYHH6cBpSO5e5SVlwM8Ot1PfHeRMZ4D9jQP88P07wEgyEI7jteusL3Whq4I9I4IbzapCiabRZ6ToiidREOx02xEwYU01Ek2AL5FiZVzBkZK0myQ+k8K311RyR97M5wKXAktCaMAokQ39LaVEVQR1Ayl+crCNQpeZ+kw4fkWOFQWDX53o4v89nW5KNUWMmsAtzbGibsrlhdDFNciOeAIDiT6DLXFJCRHD4H6bnYhJoSDXyg3FHlbMcZpmMbPohTZZ/sxUKsV/vXiCZy+EKXFbqcy1cazVx9u3lnG4ZZD331CDw6Sw58IAJk2ZcCmqpNLNS/r4pq/CYma/f/LazKqk8xqbFYVPVxbyeK+PF/p91BLlwdqiS37Pi5FFL7TJojeklOxelkdnpJ/VhTZK8nMo81opcJqHDVr++fETvFQ3+bzyiZM9XBf2cqDSTGLEy0y3uSRiSDyayg6XjT891zp83KNp7BsMssllw6Qs7QnasSx6oU2GpmmUF+XxF5Wl486FonE6+wYp8VjYWObm6Ig9nZoiWFfq5nxPkEA0SSgYJyVNaaOODK/5Qiy3mcnVtUn7aavsFp7pH20Vv98f4t7D9dzsdfJfG2rQrqG8A0vu32pkaPdEzt0AHruF15qD5Ngto+bMAG5bVUBjX4hANIlVVzFpCsYEgqgLx9jrC7HJaWW13UKOro7qt4VSBrYR99kyE7guTeHdJbnXlMhgCQptbFOaSBn8cE/jKAG+eKYDRdXIsRjpdc0Mr1tdQJc/ymA4QU2+nXynmTMtPrxTLAgcCURIGQYJw2Cj00q+riEAq6pgZF7zDfluzt6wnofXV3N491ruLfAQT16WuNAFy5IT2lhePduOJC3AlCH54tNn+ORPjnPb6kL2tkQwZWqa21cXcKEnNNyMOi06oViSpCFZ1zP5RK1dVajRdaxq2qCvJ5HEoQr2+UJEJby3JJd/X1OFrgjuzHNjz4yOTdqS7bVMyJIXWpHLyh9mFq2/+PQZvv78ef74xmo6BkLsvdCHAG5anofTotPQe7G/VeK2UFuQnrlPFlvZ7kovFymGTEd2GAY5qsIqVWewNcS9Zhv5Jp1Ck0YgJXFrKu8oyuGTlYXDzWRjb4hfH27hbOf8ZWVZLCz5f6uVZbnUdQWwmzXOdvjYUeXhAzdU88O9jZxsD+CyanzjXZvZ8PlncVk03Dadbn+MW1cVYBiS6nw7B3RBczjGOl1HBJOEj/VRkmMjHg1zqsNPIiVpsHZz57ZS7qjNJWBRuMHrYLXDOtxkJ1MG7394P+d7QritOt9412a2VeXMamPxYmbJCi1lSPY39PL82V4eP9bBikIHz5/r4x/evBaTpmISBiUeC419Yc52BVCE4I7VBQxEknT5Y+iq4K9+eZI3byrmZnSOmlWS3RF8Zwdo649gURWa+8OsK3VzuHkQb7GdJ1wGj7R3sd1l4x8bOtCF4M5cF7dFVB7d38L5TMINXyTBH31vHzV5dn74gZ2UeKZP67jYWbJC+8zPj/FaQ9+wT1mu3cQdawq4b3s5qqrgcTlo7AvjMGucbvdz4/I8rBadHIeFG5fn0TEYZW2Jkx/vb2VTuZsjLT5uXF+IX8KmMjdCESRS6W1yN20q4li+Rm9m0V0VgqSEEl2jpyPET+r99AVHR39sq0w7j9/2pRfId5q5b3sFH7u19sp+SFeQJdtHq+sK8LpVhVTnpRfZ77+ugo/cVIOe2aArZTpOrdBl5t9+W8f33rud9+yq4LsvX+CeDcVEEilaByKsLXFxst2PEJAIJvBF4ritOm6rPjy19vsjnXhGDCKTUnJ9UqX78UYO/q6JA00DmDSVMq+V5YUOVhU5SEnJgaYBogmDlv4I//r0WZ4+2XmlP6YrxpIU2sHGPhIpyY7qnOEO/rnuEJurcgHo9QW5Z10hHptOc3+YT79+BYqAqlw7H7p5GW0DEcyaoNMfI5pIsbXCy9piJ0daBslzmDndGeCFsz1srfRi0hRq8u0UBwzWN0XZppuJH+9HOR9gW4UXQdqyyqardPmj1HUFOdMZHGUIM8Sv2/tJzJP/x0JjSTadBXadn39kNykpKc+x0tIfwcLFidnfn26nI6JwuiPAH+2qYGO5h7d/ew+fu3ctn7htOYFoghNt6Vn98z0hXJkR6foyN0eaB8lzpieCDzQOkGPTudAT4kKm/8WZPtYUO9nfkb5/R5WX/U0DY7cgjGNdlYe9NoPf9AzylsLZJ/RY6CzJGq0834XVpPL1351jZ1UOjzywhQ/fejED8LZKL0+dSDdTt68q5C8fO86BpgG++rs6rCaVApeF//PG1cPNo6YKDAn7Gwcoz7GSGBHS3T/G70xXBSO3wu5rnF5kXrvO+eV2WuNJPna6iZ939NMdm11ij4XOkqzRhvjU61eiKWKcZVRSs3KyPT0x67ZqFLutnGz3E44nh6NByrw29vzlbXzyx0eIOjQijQMAXOgNs6XCM2FmFYCNZR4ONA3MuIwVeTaMjTl0KGk1piR8pbmLGJI3OM3YzGZ0ffFnyluSNdoQFl2d0Jes0x/FkGmbqA1lHlYWpSdmT3cERmUdtuoqr3tdFb/zwsp7a/B6002mEIJ1pS52VOeMe251lmuYzb1hlDE1Xl04xqfPtPB3LX1LQmSwxIU2GUNGxW/fWoqqKly/LA+A/lCc1Ii8A0IIbs5zYQARLiYbO9g0wIk2P8lZ7IqaCk/jxOYuz/T5SU3X7i4Srjmh9QZjfPvFC1h1ld0Zge2uzeOxj+zm++/dSqn34s6k5kiML1zoxKkq5A0mGBwcPRfmNGvsrM7BOcJ6fjDTZ7POYsb/dNMArgk0259IsWdwZtZXC50ZCU0IcZcQ4qwQol4I8dlJrrlFCHFECHFSCPHi/BZz/nj1fB+nO/xEEilOtF9cc9xS6eW21UWjdoz/w/kO/ruznzVCo7N+cNTzbK308mJdL6819LO8MN30uq06BU4TWyu91BbYZxQKtKzISf7Npfgn+SZC81RrXm2mHQyMMOJ7PWnDl/1CiF9JKU+NuMYDfBO4S0rZLIRYsImRCpxmHthdRXWejXdsK5/0uqd6Bvl1zyAA50mRl7F2t+oqScPAF7k4GDjUPMiKQgcOs8ZL9X0AbChzs7rYiaYqE86ZOcwaq1blEvDoXJggXHwI7xJxgJwvI753kXYTagaQUi7YjAy7anLZVZNLypDjOu4xw8CcCbE+MCJytjeZonpNDlW+OO2DEWry7NR1j27SDClHDSSGMrFYdYUStwUtszYK4LHpuHYV8rIumdo8AX7WNcAOz+Lf/zmTpnMiI76x8dErAK8Q4gUhxEEhxP0TPZEQ4oNCiANCiAM9PT1zK/E8MdHocEhknbEEv8jUZkPoCYM8h5l4SnK2KzjObai+O0T3hPk9DTp8UWwmdXivQe3aPM5NUYuNpC26NObTZiK0mRjxacBW4A2kTfn+RgixYtxNUj4kpdwmpdyWPybbyUIhkEzx4ZONtGa+YAVYazZh9Sc53Dzz+bGRSNIbWgwJFXl2XvbOfArkd/3+JTF5O5OmcyZGfK1Ar5QyBISEEL8HNgLn5qWUV5Bnen2jNpzs8MORPQ2cv8Tn7Q/F2b6ugEMlOlvdNg76Z+ZXaxKCyBxSPS40ZlKjDRvxZZy27yPtVzuSXwI3CiE0IYSNtMft6fkt6uVHSslXm7rYLXU2m8xsMptJxi49VY6mCMoqPbxUohEScCwQYZfbPu19GxwWbKrgv9v7LrkMV5t5MeKTUp4WQjwFHAMM0rkITlzOgs83dV0B/vSnR9myzMsvXmyc03N4bPrwPNpI8m8t5WXVGN6yN5Efx1hqbWZaowlKzCb+o72Xj1YW4ljEI9B5MeLL/P2vwL/OX9GuLHXdQVr6w/yvLWX8YoLzZm16i/i3bCplVZETj81EdzBKTySBX5E8LMMgL/bLXKrCoSl2utsVQaFJJ0fXsCsCVcDn6tv54qrJp2MWOtfcysBkXL8sD380yed+fRJIZxoeyfJCx4Sz/UO7qFRF4LLq3Lejgp0r82grMPNVEeY3pgTRMRVYIGVM6SRUaTUTMwzao3EGwwnyzgRwnA9Mev1iYElHb8wGt03nc/eu5e9/dZJv/tEWqvPsfO7XJ3klMwGb5zDz2btW88LZbr77cgNua9qwb2O5m4/ftpzdy3JJpNKK+vSZFn7b5ych5fDodST5Jo3ueBKvpjKQCf82CUGNzYxDVVBEerueRQBSEO8NowBJQy7ajcdZoY3gPbsqOdw8wOpiF+U5Nh5+3w6+9Ow5vvXCeV4428Mf31jDZ+5eRW8whtuqc64ryGfvXsXGcg8AmgrRlMEzfT5SU3TDuuNJdrrtHA9E2O220xlPoAvBmTG+a1EJrUgqql0cdirs94e4bpFO3maFNob7r6vilfpe7ttRgaYq/O/bV3C2M8BzZ7pxW3V0VeEr922e9P50xMX0r/NaZgolLiUXIlPnCn3VLQDJo+197HLbJzW2Wchk+2hjcFt1jrYODv9t0hS+e/82vvfebSzLn7o2aY3G+eTp5lm9njoL0ZwMRvhOy9VdUZkrWaGNoTrPzuffvG7UMUURvG51IVbT1NML32/tnfXkal9icg+OkUHhO1x2dCE47AuwdyAw7OuxWMg2nRMw1+QSDZHZOXcD9CeSFJt0OiZIkLGlK4Fm1hCGpCMZImbTKLHovOXIeW72Orkr382Nbju1joW/ATkrtHmiORLjuf7Ze2r0J1Lk64JCk0ZXPFO7ScnGmIInYnD8bDfJlCR8cxErTDrN/igWAS/2+3lxIMD2ujAb8p387ZvWLOikslmhzRMlZhPXexw81z/7+a6eeIIbTBaW+ZOctwtqWmM0tfo5G4yzqsiJy6oju5LIzgAHT3RhVhUcqkKuy8wFf5TjFwZ4+mQX//TWddyxdmFal2aFNk9oiuArqyq4df/ZKftdYylJCVKvdnNgxNLV4RHnz3SOF24saRBLGgR7Lr5ObzDG156rY2ull1zH7BOzXW6yg4F5pMCs83e1JVhn4U9bFTSGU3JfKifa/HzxmYUZMJMV2jzz+lzXrEaeE9mWXgpPHO8gHF94bpJZoc0zHk3lOo8dm6JQatZRuDhFoY3RlMUAbR7CkEbiiyT44tPniMTn93kvlWwfbZ4RQvCFFeU82zPI99r7WGYzEzck+ab0R30iEGGt04otYnD++RYOhKZeFZgtqiJ4dH8zhS4zH7p52bw+96WQrdEuAyvtFoosJjpiCf6g0MuXV1Xw72urcGoqHl3loD9M92ud9M+zyADWFLsocJh47kw373xoDweb+qe/6QqQrdEuE2UWnS8sL+U9pXmoQtAbT9IXT9KZ6T/lLPfQ3Bua1gBmpuQ5TNTk2anvDtIfTtDUH+H/vGE160s98/MCl0hWaJeJnW4Hq+3W4bXMvzrXwvkRKwd7nLB7ZyntZ/roHJx5tjyAbesLGMw10fD7NmoLHKgiHby7r3H05pmbV+RjmiDT8tVgYZRiCSKEwD0iuPF2j534mD16r7ohf30u66pG+6FNNRDduiaf40U653TJ9TtLOdsZ4FRHgJPt4+fb9jfObdfW5SBbo11mWqJxvtTQwQt9gQn3Cuy3ASus3ODUOXC8m23bi+lzqOT0xOnvDuMLxXHadHKWe6A3SjScwCd0EIKga+qv72cHW3jXzorL88ZmSVZol5m2vjCvDATpnmq1QAheK9bZGsmh1aXSqEk2rHTRVWWhP55Mt4tSsq3D4GTjIHc6zPSH45jNU399h5oH+d3pLl63unCe39XsyTadl5nu3jAeFKabwnXoKo4KJ21qutY7FoyQq2sXk50JgcmSXjQ/0zxIf38EIzrxXNnKUhcrSl1A2p28Nzj7qJL5Jiu0y0xRqYMuI4UuBCYhhj/wXW47lRbT8HUrpMbLzzWR/2oPN3alqEKhYsR5AM2Z/rvLHyPXYZ60L6eu8VJ0XXpxvTcY5+M/OjxvXm5zJdt0XmZ25Ln4txUlfPpcG72J1HDN5kumKDbrNEXTc2mpznRod38wTv+RTtZtLOB3GNyW46QlGiclJYeMOKsr3NS3+TGpCqoQ3LOuiEA8Rem2Asp0jXhK0qFJDOAjt9TwrRcusOdCH197rp5Pv36cS8UVY0ZCE0LcBXyV9Abi70opvzDJdduBvcA7pJQ/m7dSLmLao3G+2tpLd2J0M2dXBecGQuzOsWNISFhTbNVUOtsC5G/MY38qLcD2WIK6cKbpU0DXVDatyscotxFSBIGeKP01dg77g/SO6AfqwOfL8/n07ctBCGwmlYFQHK99dC15pZgXf7QR1/0L6R3tWTJ8qbGTo/6LdlbbXDZcKWh+uYNUX5h9txZTYzOTAgrLbIgSC3tHzLeVmDW8mh2DdDRu4xo1LVqZQEmBJU+lSlPxZcSoZH52OG38x0sNbPU6+PTrV1DisY5KJXmlmS9/NICPAz8Hts9rCRc5bdEEG5xWzmW20sUNg1ciMdYW2sgpc2LYrDjNKq2xBOcTCUzAWrsFq6oQSRm8MhAkltHHNpftYu0GLLOZqQvHsKkKlkzKoDKLDgheCYS5vsbNY8814/No/PGOSnZexa168+KPJoQoBd4KjLJJGMtC8ke7UvyvIi8t0TibXDa8ukbUkOTpGn2VdoxKOwEMeuNJSs06XfEkpVYzJ0NR7IqCRVXY7LJTazWx+UwIDvRiHVEplZt1cjQVBdAVgUdTKDDpNGf6fT6HxsrVeTxhSvL2o+f5l4arlwJovvzRvgJ8Rko5ZWzKYvBHG0kikeBbL9Tz7u/s4dP/fYT67tmFabdG49SHouRpKnFDUmxOW7nnmjQGEwlMqkpPIklfMknUkOx22zkRTDezDdE4p4IR9vtCDCYNTEU2TjQMsKU1znqpcp3bznMDQaKG5HQwQn8ixWDS4MAIO6wTsRitNWnz56SEh1q6aZrDBpr5YCZCm4k/2jbgx0KIRuAPgG8KId4yHwW8WkgpQSg8sqeJV87389jhNn56oHXUNRPlbUpJSWMkSjyZ5O1H6vlqczc35bjoTSQxpGS5zcyFcAxLQmLxx1lhNlNjTh+LxFLD5sjN0TjLbRZSQG8iSWuBCZtN5+CpHhyqyp7MBuSwYbBqil1Q/cmL//sRQ/LvV2lf6Ez6aMP+aEAbaX+0d428QEpZPfRYCPED4HEp5S/mr5hXnvM9QX6yv2VUAOEP9zZh1lVK3Bbesb2cs6EI/3Shgz+vLiZXV3mm18cP2vvwJ1N8vraUz1Tk87XWPrriSf6quoi6cJSnevzscNsxeqK8+mQDukkhkTAoK3fR2BNG3nRxFv9YMO2jlpASBXC+vpKeM/2cVw1GzgDrs4jS/XFnP5+uKiLPdGVntubFH+0yl/GqUFvg5M51RTT0Bnn2dLoWCMVTPH66k799+3r+7/kOvt/Wg1NTuftgOk5/l9tOfTjGdpeND59q4uNleYhkgse6o/yyZ2CUVYJdV9hyWwXHX2oFCa3NfkwmhbT5wUVGuk8ClK500TfGalRKqLWaqZ9BsxhOGfxXex+frLqyy1IzWhmQUj4hpVwhpVwmpfzHzLFvTyQyKeUDS2UObWtlDp+6fSXL8tPujBtW5tK8ycN9Z5p4sd9PxJD0j5i7OpLpH/kzzdX/19oLuonbcpzj/DhChkHUrqGNCOMRhuS2AcgxJq+hvJrK2I5weywxjbf3aK5GkozsEtQ0rC118537t/HhN6ykfaWTYMpAAaJDudJHfMObXOmO99lwjJ1uO3ZV4WQwQnTM8s9OzcRudHyHeghH0kLdUZ2D22rilX1tWPZ0o04w57XNZRu2uRpJazRO8yw6+alZyXJ+yC5BzYCafAf+AQutbemawCQgMkY8hSaNQOqiCF7zhdjusmEAJ4IRVtst1IWjbOpJceRgw/BQ3qQIttfkcLhpkEhm9aA/GGd9TOGIZbQgNCFom8Ch2wDcmjqq4z8ZJiF4sDRv5m9+nsjWaDOgO5bgd30X7Q6iEgpMGo4RHh1d8SSBMV+0AA76w/hTBm5NRRMCIS7OF+XYdPKcZmImhdXbRu8wdwbGi2Zs4OQQG5xWwjNYNM/VNf570zLuzvdMe+18k63RpsCQktOhKPceqhuXk+lwIMJOt52WaJxSs44qBIFkCq9mDDdvI6VyJhRlk9OGzWRQ1e+huclHzZo8DhzoIMdroaXEjNWkEomnUBVB0jK+DpBIrlNNiJTk1REZlU1CDDflU/HN1eWjjPxeruvlF4dbqW/pAM1EgUPHZrUST0m2VOWR5zCzvTqHUs+lm8hkhTYJPfEE7z/RyEF/CLOisM1lY43DSms0zvFAhJ5Ektd8IRTSnXGAGouJgWSK69x2gimDUMpgl9vOQCKJR9doiMQYTCQxrXJiW+0ieTbdFJ9r8ZHvi9GRaTqrCh3scabLIYCtLhuqENSFoixTNDR/AjLu8SttFsQM+lw3eezc6HWOOvalZ8+OyFMVzfykJ6WfOJkeaWuK4IM31fCnd6ycdS7SkWSFNgGJlMH7jjdwwB9mld3CjzbUUJKJDftOS88oI5eR9ZwrBTcMSmTrAG6bhsms8Zx96IoYFiGISYilDBKGRM0kMkukJO0j8kj1+qLsDLo4YwO/ku6bAeTqKjFFUOdWIJmiyKQRTqWISYEmRg9MRiKA3w+GuGHfWX65pZZ8k059d3DCZGhjSRqSb75wnmOtPr5636Y5+3pkhTYBB/0hbs9x8jfLSjjqDw+LDKAvMbFPxq4gNB1p5Uzo4vnlt5SNumaoeVMAoSnYnROH7PjCCY6+0gbAzt2l7CXEBoeVuki6mXZrKrU2M4FkirOZRfadbvuwXelYhvR3IRLjb080opz2j0uaNh0v1/dyz9de4r8+sJPaAuf0N4whOxiYgLUOK5+qLmanx8EHK0ZnhLy/JI8cXcU5xqxPCyQZCI0W4cDBbm4YkIzcvJmjqWxoi1Nywsfe/W1T9n/WVXvpsClscdk4F05Hf/gSSZqicQ74w8MiA1CTBmvNU8ea5WkqgeYQvzneids6uxTaQqQjez/w8AGMSQYlU5EV2gQ4p8gBUGIx8cZ8D4GhwYGUVCYFwYHxezN7A3H6m/0UyosfswRCgRhtLQEqa3OorvVM+lqqpuCwaBz2h4lmvtzgBF/y5o44Bx+r5/yvGtjpk1SZxotoi8mM65Ue9uxLL1N3+ma3lxTSYmvsC/Nyfe+s7802nbPk6V4fj2RyM62NCwb29dAXSdA1yX+5p9rNKeXiuYFkCueGHFwDUZyVTl6TCTYsy+HY+bR1wbJ8OxcyO9iP1vWxNSnRlltJZPrhuhCssJkxKQqHA+mVCLPdNDxlogYTlLnNuJpjWJw6QhHEeiJ0+fpZ5rHgseqc6vBjnkUqblURSCkxJGyr9NI1IpBzpmSFNkuG6iarBHdHlPNT+GeU5dg4NEGsYXM8QdFNxdQhKQ4LgsE4FbeVUTmQ5KXDnVy3Mo9eX5R43KChO4iy/GLzqggwK2JU2HYqM1otz7ES7YvS2+ijO5gul8uqUZtvp9JmZl/jADuqc3BZtVnVaClDIgR4rDrmAguhOYw+s03nLHldrouPl+Wx0mZCcUzdzykosLGuPsxEBhudiSQ9iSTnNANfKE6pokGpnV27Smkos2Ba4aGpP0x/KM6aM0GWZaq0mCE5FIgMBzcqwLkCnV0r8mgdiHCqI0Cxx8qOai9ril0kkpJDzT4OZUaYhiFZW+wiGJudh5qU4I8nCQr4nTZ748Cs0GaJAJ7uD3IkEqfTpbJ17cQBnDaTimJSiVXaL+7NnIC1cQV/JMEZmaDLLIhV2GnUJHjNw3bzp5t9dL7Qxg1dyVGitasKu2IKjn297DnXO3zqaKuPSDxFXXdgeFlriANNA+y50M/2Ki+KKigstlO9zIPJNLkUCovsLL+3Bu89FZzJ06mxzX6KI9t0zpLmaHx4BFivS/I8E4/01mwqzGQannqElptrxbwuH81uxqKr7B8MIoCULlixvQiXzURPPEHinI8DR7rYvauEAx7BZpeN/b4QRgz6eiOjwqAdZpXeYHw4N9VE+GwKqTtKaTIk+bqG0xfDZtcJ+GIMDKZHswKoqHQT3+DleOziCLfamhXaZec3Pb5Rf++1S1bm22nqGT2HdXB/O7t3lvCqC/JMOrU2MyeDkeHRqgqscVg5EI4SLtIhFsOdSrLRZccqBC8PBFHscJOUxBQYSuJ+7kg3q+6oGJ4z68zXycuz0dubHhjk2E3kOUyc65p6niwaSqIJQQxJTyIJW3MA0IULt6oggRJVoy4RJzoiB0KernFPnnvWn1tWaLPAn0zxvdbRodDLkwr+8PgBgZRwaG8764udGBu87PWFWG4zU6soBA0Dh6oOjxqH8CVT7PWF2B1V8O7rwpDwUnR0X2pljZd90djwynxjLMHudXn0vpBODeRx6DCDhBx9vWE2Jr28Kkav4SakpDezVts3QTTIHXkuCsyzm4ODrNBmTGcswafPNI8L03ElJS2hyTvHQhG0GClQoC4cw6MpWBQFq6pgUxTCY4yV83WNntMD+CMTd9YT0dTwVMcQRsYHd9vGQoIenXYd8gMxegKTx6jV3lIOwQRYpnrX48mZYo5xKrJCm4aYYfDX59p4oneQ/sT4/3BraPLwHIdZo22NE/+ICmYwaeDRoCkcY53Tyr4xy0Ya0NI8eQaWUIWNsf2+11xw3XWlnHVAT2bOzr4rj3X1YU40TOyRduQ3FzCZFEy3lRCf4cbiMrNO6RxqM8gKbULCyRQ/6xogKSUPt/dxNjR+zsmmCCyqgphih2FlkYODQjJ2x+LgiJTZY4cLOYoCXjP9A7Fx+xx3bSriBZMx7vk2OW2cN8UpM5voyTTHtS4rAzWCqlCcxu7xa6CKAjl3VtA0QQ6qsQyVsSeRZKvbPu31E5EV2hh8iSRvP3KehCE5HR4tMIciWOe0EZeS44EIuoS4d/L1RVu+dcqpjX2+EEUmbdjXFuBkLI5pZz43pjRe/W0jUoJFV1i7Io/6Qp1Sszqq+V5tt3A0EMYAyi0mnKogZkhMiuC8Jlm71gsjhFbutZLnNNNjpAhJiVtVWY1KpyppnER0xSaN/mSKL64oZ419brFpWaEBj3UNYFYEXbEE32jupi2WQAFuzXEQTBrDPrRNkfioXUm+ZIrXNNi9Ko9DZ8av/yV8cciduhNkyXTcq6wmGiNxLIpguc3C88EIO1fkcbyuj9U1Xl4p06m0aDRF49gVhU0xQX+Tn+R6M5qAuEynZNQVBZsqhjcSW70WNu4sIV5gwXZigO7BKIebB6ktcNDyeBNmk8KRuMHmG8poHFNZFZg07KrCYCLFR8oL+IPinDl/xte00KSUPNXr4xvNXZwMjq69DOBUMDocwDgZqpR0dk0cntPWGUSvNpOYoFbb7LRiURSCKYMqqwmXqrLdZeOgP0w4ZWAA5yrMWJpUkgVpsTZF49RYTOSbNBI9ARrOD6I0+tixuYhGj0rKkMP9yFqrmTyTxpFAmKhHQDzGDZVOWjJ9tvru9HxdPJ5+b4debuW6u6sRSQNUATadSqsJ3ZCYc3T+tOrSkpldk0JLJpP0Jg0eONHIkTFTDADrHVbMiuBcODalyABWxxXqByZeZDbpCpvddg77w9g1ZXTfTAj2+EK4VIWklDQaF6dIhty7Y5qg9tYy9hsXm7QL0TgXonGuM6dXDYyU5MCBDgpcZrp35YIQVJh1IoYxbk/oecfkzbgADj/ZMOrYIeD+nWV8/q0bp/wMZsI1uQQlhCCUSPD11RV8ddV4M2GLonDAHx7enzkVjvjkI7a2/gj9fRE8uoZDVSkcsTs8aUg0Af6UQXiSyA+7plInJinDmIXtRMpgc1BgIj1BXDPB7H1PMsmWm8vHHR/3uiMyLbcPhoknp9/4Mh0zEpoQ4i4hxFkhRL0Q4rMTnH+3EOJY5udVIcSl/wtcRlRVZZnTTq3dwh8UedEzlp9DH+9+f4hNznSnV8CE2eqsiqBS0Tj52kUbkjVVHkrLnZTl2ihwmdm2vZh6zaAnkaQ1liBH17jRY6fGauZEMIKasRudjAqLecIa1akqpMbMs1VvL6a3NcBu3cxgMkl/cvw8XFKCEZ9aNHl2nd3LclhZ6GBjuYfPvmH9vOQqmC8jvgbgZinlgBDibuAhYOcll24eMQwDRVFIpVKoqkpvNEZjNMF7TzSQlDK9rmc10RBJN2G5ukaZRWeFzYIvmeLgCJee7SGBM89CfTDGhlV5SJeJnWYL77ipmrsOnmOd2cTLoQgrYioFJjHsyH06FGWn286FSAxVwC63g5cHJ3coUifRYNSQhHwxLBaNaGbl4OyBDsTNxdQlYjDB4LHKrGM/7eNI3cTzanaTyvI8C5sKdd77urUUu82YNRUxxT/CbJiJVIeN+KSUcWDIiG8YKeWrUsqhd7CXtOPQgkLJ1Eqqmq633LrOWoeVb66u5MHSPG7wOkhlJi7vK8rhvzYu48B1a/mvDTXsGlG7VRmC4y+30nyomy5d8kqZiVdd8NYbqyizmFhltxBTBTtcdmKBBLX+0TXI0Ne2xWmnNRofZ5UwExJScqHWzuDNhcNNYSiYIPCbZjaZxjeZuhCUBgzOTyIyAKtJxWox89OTAc51BbDo2ryJDObJiG8M7weenOjEQjLi01UFq6Zyc66LXJPG7weCXOdx8pnqIh4suTiMF0Lw58tK+UVNEQ+vrGBZa6ajHkmiZ74Il6rQHUugKYJ/XVmORVHY5w8RcGu0netPiysjYl0R/FN5EXYjvVlkJDVmE2UmnQ1mMzdardinWLOMZPp1qRFpGAVg6ro4MCnSNW4LK5h/24a56+Koeqx+LJoCqSQNPUGK3JZZ7yeYCTMZdc7EiC99oRC3khbaDROdl1I+RLpZZdu2bVfPUHUM/7uykHcU5VBs1lEm+C9WpeQTPzxBfyhO0pDcs76It+ys4KGAjwO+EBFD8r4TDfxm6wpW2C24MmHSwkjbf67oSBKMpdhTZWa708Yzv2tgz4V+dl1fyn5nusZZo5k48asL2G06cSnp211Erjr1HJwKNJ3pG3UsNBhje2UueksYW2+IQ+0+NtxeScCqsi7XhC2UJNYd4WjrxSiUlJQIzYSmClYXOSlyzXIBdAbMRGgzMeJDCLEB+C5wt5Syb+z5hYwQglLL5DP8Qgg+eftynGaN5YVO3BaNEq+NNVE3bz5Yh6YImqJxGiMxqq1m3pDnpjeexH4hQGN/mMHWBPfsruDTG8s5erSTvRfStdzhV9pw2zUUoXAiGEcA4XCCZcVOTqoGSiJtOWpG0JVMskzTaUsl8acMElKSAtZsLCDWGEQRcLLdz4W6fkpWuan2munuC7P9xlJSTjNa0iBeaifcEaLtXITaW8tAQqkvQaJ3gK13ryXpj/NgTQH5rkvfmT6WeTHiE0JUAI8B75FSLsyk3peApiq8e2fluONlFhPX5zj4fZePXUH46ZN1POXQ2VeoUx+Lc2+li4dvXE5tgQMpYc+FXn5rxNi6Np+T5/qIJgwqXFbO94RGNRsD/hhFhpuCwQS5QYPfH+5AUQTnUhIJFOXbsF9XSG8qxWCBGcUfp/3sANvXFyAFnJQSfAnyKuyoKFg6QpiTgr5KOzkDCdw3l3FEpCgza5TW5JCvl1Jls/DWmuLL9xlOd8EMjfj+FsglbSkKkJRSbrtspV5AfG11Ja/oPdz//f2kMv0mj8fMXZuL+PKWauyqipSSv/7FCR7d18yyQgenNrqo6TDjCyewmrRx81T9oTj8tpXBzN+ri52c7kiPTgXQ0xMm9FQzBbk22rflsLrQRmFnmP6eMNraHGo0lZjFwG9RcDUEMCcMOhMpnEVmenTBCSNOgUkngeCQP0wRBuG2GI919LLCaedDZfmjYs5SUnI2FKXCYsKhzXz31EhmtDIgpXwCeGLMsW+PePwB4ANzKsES4PrafP7jge3sudBHY2+IilwbN9TkYVUUpJR8+dlzPLovHZgYiibZ7bBxeovAr0gCMQWaJh8NCpGejB3ZoRWA2a5RsD6XM/EEBWYzXcEYK3YW85IRhzDk2zRqe+Kk1nkJNvgxzFZ+G4mwa5mLiC9EUzTOVpcNh6rQlZA06ibyUgYNgRC/6dGJGpIX+wPUhaP0J5KkJDy5bQVrp/DLnYprcgnqcnDTinxuWjF6o4phSA42DfC15+qx6QpmXcW9MZdXQpHM7LDAPUnisCGkBGeBnQ07CjmWSvfjinSN3mSKBg0qhAmbBNdtpbwUvbiM1ZNI4iww4zIMUv44ects5IgEDSNGuieCEWyKgl1VaB0REfLEwMWlq6EQob+sLp6zyOAaXYK6UiiK4PlzPawrdVHitTEQTiAaglzflmBHSLC7OUbz6X7yHFNbGRiVDvYnYsQMSdSQNMYSBFMGLbEEzdE4e2MxcicISLwQj3MkEKGj1sHzqRhrHDa6RoQkxQzJQDI1SmRjGapJf9Z1abnZszXaBASiCZyW0V9cMJZk7/k+2n0ROnxRmvpCdPljbChzU+iy0OWP8sDuKipz07E2sWSKaMJASsmJtosRs2dafKNmJRUBrknmrRwOndqbyqhj6j2Yu9x2euKTXzO0ByBqzH3NsnuK558JWaFNwERr3L851s5nfn581LGtlV5+daSdvsxu9ccOtbGrJie9qaSuh2RKTiqiITaVe4Y3944lv8jB3tTkO+GHkDAqX/tI1jks+JMpeuJJrECpSadtBlG1I7Eqgr9ZVjKre8aSFdoETDQz7oskKHJZ6A3GSGaUqArBYCQx6pqnT3aNuq9/CssEq0mlsW98mNIQrU0+Sle7pxXGYX+IcouJlkwfrdSsU24x4U+mOJGJsyvSNVpf6UBGU2wsdqDpgrYyK51TZEZebjPzhnwPHyrPxzvHTSlDZIU2Bb5IArdVR0pJNGEQjqeznwyxr7GfAqeZMq910lppKiLxFJvLPfSHYpzpHL8PM5Ew8AqFtmmeZ7PLTm88SbnFRCiVoi2WGLdbSxeCjo4gSOjvTy9TOc+b2H5zGYcSMcQYI78/Lsvj87Wl87bemRXaJMSSKTZ9/hluX12I16bz2KG24ZpsJN2BGE6LxuZyNx2+KIoQtE9joGLRFaSEApeZ/Y392EwaFk0hmjQwmxTKqz00nh8gmZQ4p4h3A9jgsE5qwDeEVRGUGIKeMU8VCMQ5/vgFCnOtxGNJKpZ5OVtiJmQYfLC8YF4X1bNCm4R9XT7WV+fw7Kmuaa89P2KXukVT2F7lZSCcoH4SV8VitxWnWUMIaOmP4IskWFviwm5S6ROS8zU2lGV2tqRUQiYBMVhjt9CXSI4aNULaWWgsY3dWrdJMHP31hUnL39+XruFywwZ/aXOz3yYJpaYP+pwNWaFNwjmZ4tgyC+ZmhdgsIkyjSYP9jQOsK3WxszqH1xpGTwuUuC009obGRSWcbL84Mi1LGfSsc6edtzN9/BqrmVKLzov9wVH7MHvG9LEURvvqFusa+b4k5zKCTE1QK5s1hbdsKuX/vnUduqpclpn3rNAmQRWCHKnQP8cw5qEpjW2VXqSUKIqgPxQfVftNRtAfo1DT8I0YcT7e6+Mj5fmcDcUIpwxu8jrAMAhISV88OezpoYiLo+Z1djO7kjr7zraxrdLLvsbRon/njgresL6YXTU5aDOwUbgUskKbgLZonJ919mOSsLbSw8mmwTk/14GmAbZVetnfOPky0xCaIthU7kkb30nByOgEj6aiAi9uX8kXGjuxK4LVDitSppNmlCkqdxR42eW0UmG3UmjWKB7ytN1dS/tgmBfP9fKLw23sb+znHdsr+Oe3rZ/z+5otWaGNwZ9M8eGTTel9kRp4Kh0wR6EN9aVr8h3EkgYn2n0TefINs7LQwekOP1JKcl+J8fF7atkbi3FnnovX5br4TmsPbzlSzzuLc7kr10mRJR1N61QFubrGBvfkqaxLPDbeuaOCd+6ooH0wQu40qxHzTVZoI5BScseBszRGLjZZZywGJk2ZdieQIqDUa6WlP8Ltqwu5aUUeq4pcVOTYKHKnAwlPd/j5u1+eHNeEDVHstvCRm2u4fW0xZk1BCEE8meTfmrq56+A5Ypk28WiglUBNMR+vTKdCvDXPM6v3WTIPmVBmS1ZoQMoweLrPzysDwVEiA4gKwZbanAl3oo/EkHD9sjxsq1X+7M6V2CZIvLq62MWPP7iLh/c08u8vXuCDN9VQ3xNMW4K2+/jtmR5sZp03brq45cKkaXx2WQm35Lr4zLlWzoai/EGhd1hki4VrXmi+WIz3n2qhN5HkzARmLgDdJRbsDSqh2MRDfl0VlHlt/OXdq3Hbpl5yUhTB+66vZmOZm2UFDtzWdBMWTaR49XwvtfkTJ4vY5XHwxJbl/LJ7kLvzZ2+Ed7W55oV2IZrg5WkSpdbrkptW5rHv2MRzaooQvO36ymlFNpJ8pwXziCBCi65y26qpaym7pvKuktwZv8ZC4poOE2qLxnm4fWbbG4qcOisLJ+5sb9xcxLJa76xeuzzHhmUWXv+LnWtaaF9o6ODHneOnHYa2uVkUgU1VKDPraG4rbYMRVhWNbtpMqoI9BcY82AYsZa7ZpvNrTV38dIzIvJrKV1ZXcDYUJWYY3J3nZq3DSlM0zrM9g5RdX80je5tQFTE8wx5PGXR1BCmceabpa5JrTmjnw1Eeae/joZb0Bma7qhDOxOS/LtfFnXlu7hzjOl1lNfPHFYXEinK4fU0hwWiCv/j5cfqCcRwWjZ995LoJR5lZLnJNfDpngxH+pr4NBUF9JEpr9GIITdqiSuFPKvKpsU29cdZs0tlQ5gHgAzdU8+K5HgqclqzIZsCS/4TOBCPcsv8sObpKvq6PEpkq4L7iHHZ5HFTNMknDA9dXc/91VVM5h2YZwZIfDHRmQpzfVujlme0reHh9NWvsFjQBq+wW3l6UM2uRDaEoYl5jtpYyS75G25nj4rVdq6mwmBBCcGeeG6eq8LYj52mPJuiNJymco6V5lpkzX0Z8Qgjxtcz5Y0KILfNf1LlhVRUqreZRNc9qh5U/LPSyd9fqrMiuENMKbYQR393AGuCdQog1Yy67G1ie+fkg8K15Lue84tU1vramEvclbrjIMnPmxYgv8/cjMs1ewCOEuHyOIVkWHfNlxDcjs76FZMSX5coyE6HNxIhvRmZ9UsqHpJTbpJTb8vMnTqiaZWkyE6HNxIhvRmZ9Wa5dZiK0YSM+IYSJtBHfr8Zc8yvg/szocxfgk1J2zHNZsyxi5suI7wngHqAeCAPvu3xFzrIYmS8jPgl8bH6LlmUpseSXoLIsDLJCy3JFEHKGaY7n/YWF6AGaxhzOA6bebnR1Wejlg6tbxkop5YTzVldNaBMhhDiwkN28F3r5YOGWMdt0ZrkiZIWW5Yqw0IT20NUuwDQs9PLBAi3jguqjZVm6LLQaLcsSJSu0LFeEBSG06ULF5+H5y4UQzwshTgshTgohPpk5/jkhRJsQ4kjm554R9/xlpjxnhRB3jji+VQhxPHPuayITIy6EMAsh/jtz/DUhRNWIe94rhKjL/Lx3inI2Zp77iBDiQOZYjhDi2cy9zwohvCOuv+JlnDNSyqv6Q3qh/jxQA5iAo8CaeX6NYmBL5rETOEc6LP1zwJ9NcP2aTDnMQHWmfGrm3D7gOtIxeE+Szk8K8FHg25nH9wH/nXmcA1zI/PZmHnsnKWcjkDfm2P8DPpt5/FngX65mGef6sxBqtJmEil8SUsoOKeWhzOMAcJqp03W/GfixlDImpWwgHZWyIxOe7pJS7skEEjwCvGXEPQ9nHv8MeF2mJrkTeFZK2S/TeeefBe6aRfFHPu/DY15voZRxWhaC0Gabs/2SyDQXm4HXMof+JLNz6/sjmqXJylSaeTxRWYfvkVImAR/pHKazeX8SeEYIcVAI8cHMsUKZie3L/C64ymWcEwtBaDPO2X7JLySEA/g58CkppZ/0bq1lwCagA/jSNGWaqqxzuWcs10spt5DeVfYxIcRNk1x3Ncs4JxaC0K5IGLgQQictsv+SUj4GIKXsklKmpJQG8B3SzfhUZWrNPJ6orMP3CCE0wA30T/Fc45BStmd+dwP/kylP19COsszv7qtZxjmzAAYDGunOZzUXBwNr5/k1BOm+ylfGDhJGPP7fpPs8AGsZ3dG+wMWO9n5gFxc72vdkjn+M0R3tn4zoaDeQ7mR7M49zJiijHXCOePwq6X7SvzJ6MPD/rlYZL+k7uNpCy7zRe0iPBM8Df30Znv8G0k3BMeBI5uce4D+B45njvxojvL/OlOcsmVFb5vg24ETm3Ne5uLpiAX5KulO+D6gZcc+DmeP1wPsmKWNNRjhHgZNDnwPpPtTvgLrM75yrVcZL+ckuQWW5IiyEPlqWa4Cs0LJcEbJCy3JFyAotyxUhK7QsV4Ss0LJcEbJCy3JF+P8B3wXUtrkMoOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a plotting for authority\n",
    "authority = geopandas.read_file('CTYUA_DEC_2021_UK_BFC.shp')\n",
    "\n",
    "#initialize empty set\n",
    "pvaluereg = np.zeros(len(authority['CTYUA21NM']))\n",
    "#loop over all authority\n",
    "for i in range(len(authority['CTYUA21NM'])):\n",
    "    for j in range(len(authoritynames)):\n",
    "        #if authorityname corresponds, get the value\n",
    "        if authority['CTYUA21NM'][i]==authority_pvalue.iloc[j,0]:\n",
    "            pvaluereg[i]=authority_pvalue.iloc[j,2]\n",
    "            break\n",
    "authority['pval'] = pvaluereg\n",
    "authority = authority[authority['pval']!=0]\n",
    "\n",
    "pvaluebull = np.zeros(len(authority['CTYUA21NM']))\n",
    "for i in range(len(authority['CTYUA21NM'])):\n",
    "    if pvaluereg[i]<0.05 and pvaluereg[i]!=0:\n",
    "        pvaluebull[i]=1\n",
    "authority['regtspval'] = pvaluebull\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "authority.plot(column='regtspval',categorical=True, ax=ax,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38345ad2",
   "metadata": {},
   "source": [
    "For understanding the positive or negative correlation of wages on unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395db81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc256274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percentage of negative sign of wage coefficient in regression is 0.9852941176470589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a plotting for authority\n",
    "authority = geopandas.read_file('CTYUA_DEC_2021_UK_BFC.shp')\n",
    "\n",
    "#initialize empty set\n",
    "signreg = np.zeros(len(authority['CTYUA21NM']))\n",
    "#loop over all authority\n",
    "for i in range(len(authority['CTYUA21NM'])):\n",
    "    for j in range(len(authoritynames)):\n",
    "        #if authorityname corresponds, get the value\n",
    "        if authority['CTYUA21NM'][i]==authority_pvalue.iloc[j,0]:\n",
    "            signreg[i]=np.sign(authority_pvalue.iloc[j,1])\n",
    "            break\n",
    "authority['regtssign'] = signreg\n",
    "authority = authority[authority['regtssign']!=0]\n",
    "\n",
    "negval = list(signreg).count(-1)\n",
    "posval = list(signreg).count(1)\n",
    "print(f' Percentage of negative sign of wage coefficient in regression is {negval/(negval+posval)}')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "authority.plot(column='regtssign',categorical=True, ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a259420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percentage of negative sign of authorities wage coefficient that is significant in regression is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Here we compute the percentage of authorities that has significant values and turns out to have a negative impact\n",
    "#initialize negval to store authorities that is significant with negative correlation. Same for posval, which stores positive correlations for number of significant authorities.\n",
    "negval = 0\n",
    "posval = 0\n",
    "for i in range(len(authority['regtssign'])):\n",
    "    if pvaluebull[i]==1:\n",
    "        if signreg[i] == -1:\n",
    "            negval +=1\n",
    "        elif signreg[i] == 1:\n",
    "            posval+=1\n",
    "print(f' Percentage of negative sign of authorities wage coefficient that is significant in regression is {negval/(negval+posval)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d69d89d",
   "metadata": {},
   "source": [
    "# Multivariate linear regression for time series with respect to other variables\n",
    "\n",
    "Suppose now we are interested in unemployment data in all years and its relationship with time series of earnings if we consider confounders in time sereis. We want to include all of the avaible data of confounders in all years and look at the relationship for unemployment and earning. Here, it is better to consider multivariate regression with more than one predictor and more than one response.\n",
    "\n",
    "Consider the following equation:\n",
    "\n",
    "$Y=X\\beta +\\Sigma$\n",
    "where $\\Sigma$ is the n×p matrix such that $X_i\\sim \\mathcal{N}(0,\\Sigma)$ (multivariate normally distributed with covariance matrix $\\Sigma$, Y is $n \\times p$ response matrix and $X$ be an $n\\times (q+1)$ matrix. Expand it out:\n",
    "\n",
    "$\\begin{pmatrix} y_{1,1}&\\cdots& y_{1,p}\\\\\n",
    "\\vdots&\\ddots&\\vdots\\\\\n",
    "y_{n,1}&\\cdots&y_{n,p}\\end{pmatrix} = \\begin{pmatrix} 1&x_{1,1}&\\cdots& x_{1,q}\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "1& x_{n,1}&\\cdots&x_{n,q}\\end{pmatrix}\\begin{pmatrix} \\beta_{0,1}&\\cdots& \\beta_{0,p}\\\\\n",
    "\\vdots&\\ddots&\\vdots\\\\\n",
    "\\beta_{q,1}&\\cdots&\\beta_{q,p}\\end{pmatrix}+\\begin{pmatrix} \\epsilon_{1,1}&\\cdots& \\epsilon_{1,p}\\\\\n",
    "\\vdots&\\ddots&\\vdots\\\\\n",
    "\\epsilon_{q,1}&\\cdots&\\epsilon_{q,p}\\end{pmatrix}$ \n",
    "\n",
    "This is just a superposition of:\n",
    "$\\begin{pmatrix} y_{1,i}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n,i}\\end{pmatrix} = \\begin{pmatrix} 1&x_{1,1}&\\cdots& x_{1,q}\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "1& x_{n,1}&\\cdots&x_{n,q}\\end{pmatrix}\\begin{pmatrix} \\beta_{0,i}\\\\\n",
    "\\vdots\\\\\n",
    "\\beta_{q,i}\\end{pmatrix}+\\begin{pmatrix} \\epsilon_{1,i}\\\\\n",
    "\\vdots\\\\\n",
    "\\epsilon_{q,i}\\end{pmatrix}$ \n",
    "for $i=1,\\cdots,p$.\n",
    "\n",
    "Thus, we can calculate all regression for the above equation to get $\\beta_{:,i}$ and append them together to get beta matrix. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea51dc",
   "metadata": {},
   "source": [
    "Here we consider the relation between unemployment and wage only in time serie data analysis. First create a function to initialize the xvariable and yvariable we required for multivariate linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cac18bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here Initialize the xmatrix and ymatrix for such model as a function. The function is for year i of the unemployment and\n",
    "#it is regressed with all time series of x variables. \n",
    "def Initializationtsyearunempearningonly(i):\n",
    "    yvec = np.zeros([len(authoritynames),1])\n",
    "    for j in range(len(authoritynames)):\n",
    "            #only take 2008 data onwards\n",
    "            yvec[j,:] = std_values[authoritynames[j]].iloc[4,i]\n",
    "\n",
    "    xmat = np.zeros([len(authoritynames),len(year[4:])+1])\n",
    "    xmat[:,0] = 1\n",
    "    for j in range(len(authoritynames)):\n",
    "        #only take 2008 data onwards for earnings\n",
    "        xmat[j,1:len(year[4:])+1] = std_values[authoritynames[j]].iloc[-6,4:]\n",
    "\n",
    "    return yvec, xmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d23be2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>beta_3</th>\n",
       "      <th>beta_4</th>\n",
       "      <th>beta_5</th>\n",
       "      <th>beta_6</th>\n",
       "      <th>beta_7</th>\n",
       "      <th>beta_8</th>\n",
       "      <th>beta_9</th>\n",
       "      <th>beta_10</th>\n",
       "      <th>beta_11</th>\n",
       "      <th>beta_12</th>\n",
       "      <th>beta_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Constant</td>\n",
       "      <td>0.351943</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.440283</td>\n",
       "      <td>0.924750</td>\n",
       "      <td>0.822374</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.035255</td>\n",
       "      <td>0.371528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>earnings,2008</td>\n",
       "      <td>0.541314</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.100505</td>\n",
       "      <td>0.208165</td>\n",
       "      <td>0.906303</td>\n",
       "      <td>0.247675</td>\n",
       "      <td>0.556308</td>\n",
       "      <td>0.032916</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.622187</td>\n",
       "      <td>0.686393</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.166409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earnings,2009</td>\n",
       "      <td>0.502030</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>0.370866</td>\n",
       "      <td>0.773065</td>\n",
       "      <td>0.386662</td>\n",
       "      <td>0.933721</td>\n",
       "      <td>0.244617</td>\n",
       "      <td>0.763030</td>\n",
       "      <td>0.730143</td>\n",
       "      <td>0.495467</td>\n",
       "      <td>0.396012</td>\n",
       "      <td>0.640606</td>\n",
       "      <td>0.634014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earnings,2010</td>\n",
       "      <td>0.627303</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.067401</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.443167</td>\n",
       "      <td>0.157330</td>\n",
       "      <td>0.813167</td>\n",
       "      <td>0.906292</td>\n",
       "      <td>0.216099</td>\n",
       "      <td>0.688191</td>\n",
       "      <td>0.806911</td>\n",
       "      <td>0.512133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earnings,2011</td>\n",
       "      <td>0.785758</td>\n",
       "      <td>0.725355</td>\n",
       "      <td>0.112005</td>\n",
       "      <td>0.904701</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.141651</td>\n",
       "      <td>0.265979</td>\n",
       "      <td>0.845823</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>0.988670</td>\n",
       "      <td>0.207667</td>\n",
       "      <td>0.224546</td>\n",
       "      <td>0.448043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>earnings,2012</td>\n",
       "      <td>0.778061</td>\n",
       "      <td>0.262423</td>\n",
       "      <td>0.553152</td>\n",
       "      <td>0.128754</td>\n",
       "      <td>0.141317</td>\n",
       "      <td>0.369947</td>\n",
       "      <td>0.463240</td>\n",
       "      <td>0.506434</td>\n",
       "      <td>0.409626</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.328180</td>\n",
       "      <td>0.003935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earnings,2013</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.774735</td>\n",
       "      <td>0.162517</td>\n",
       "      <td>0.193070</td>\n",
       "      <td>0.657653</td>\n",
       "      <td>0.415445</td>\n",
       "      <td>0.050021</td>\n",
       "      <td>0.341824</td>\n",
       "      <td>0.277262</td>\n",
       "      <td>0.091713</td>\n",
       "      <td>0.212074</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.098619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earnings,2014</td>\n",
       "      <td>0.692685</td>\n",
       "      <td>0.261713</td>\n",
       "      <td>0.858547</td>\n",
       "      <td>0.194765</td>\n",
       "      <td>0.469335</td>\n",
       "      <td>0.312604</td>\n",
       "      <td>0.085723</td>\n",
       "      <td>0.776779</td>\n",
       "      <td>0.891051</td>\n",
       "      <td>0.632566</td>\n",
       "      <td>0.324320</td>\n",
       "      <td>0.882908</td>\n",
       "      <td>0.220307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>earnings,2015</td>\n",
       "      <td>0.773848</td>\n",
       "      <td>0.221365</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.821078</td>\n",
       "      <td>0.796786</td>\n",
       "      <td>0.707739</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.800173</td>\n",
       "      <td>0.455333</td>\n",
       "      <td>0.596580</td>\n",
       "      <td>0.390166</td>\n",
       "      <td>0.570340</td>\n",
       "      <td>0.645281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>earnings,2016</td>\n",
       "      <td>0.480126</td>\n",
       "      <td>0.630262</td>\n",
       "      <td>0.110059</td>\n",
       "      <td>0.415929</td>\n",
       "      <td>0.924498</td>\n",
       "      <td>0.900963</td>\n",
       "      <td>0.046638</td>\n",
       "      <td>0.863978</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>0.518778</td>\n",
       "      <td>0.894858</td>\n",
       "      <td>0.853393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>earnings,2017</td>\n",
       "      <td>0.095681</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.121555</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>0.468618</td>\n",
       "      <td>0.123357</td>\n",
       "      <td>0.188788</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>0.993442</td>\n",
       "      <td>0.942238</td>\n",
       "      <td>0.988921</td>\n",
       "      <td>0.525361</td>\n",
       "      <td>0.486641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>earnings,2018</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.719239</td>\n",
       "      <td>0.565170</td>\n",
       "      <td>0.158467</td>\n",
       "      <td>0.971019</td>\n",
       "      <td>0.574890</td>\n",
       "      <td>0.335132</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.704058</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.268424</td>\n",
       "      <td>0.932823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>earnings,2019</td>\n",
       "      <td>0.612681</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>0.222512</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.329555</td>\n",
       "      <td>0.875114</td>\n",
       "      <td>0.925385</td>\n",
       "      <td>0.979428</td>\n",
       "      <td>0.486696</td>\n",
       "      <td>0.653518</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.144962</td>\n",
       "      <td>0.117658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>earnings,2020</td>\n",
       "      <td>0.545321</td>\n",
       "      <td>0.376536</td>\n",
       "      <td>0.094252</td>\n",
       "      <td>0.834384</td>\n",
       "      <td>0.336437</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.359016</td>\n",
       "      <td>0.371424</td>\n",
       "      <td>0.668957</td>\n",
       "      <td>0.812787</td>\n",
       "      <td>0.962868</td>\n",
       "      <td>0.257909</td>\n",
       "      <td>0.341384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variablename    beta_1    beta_2    beta_3    beta_4    beta_5    beta_6  \\\n",
       "0        Constant  0.351943  0.001005  0.002348  0.002385  0.000003  0.440283   \n",
       "1   earnings,2008  0.541314  0.502468  0.100505  0.208165  0.906303  0.247675   \n",
       "2   earnings,2009  0.502030  0.050303  0.370866  0.773065  0.386662  0.933721   \n",
       "3   earnings,2010  0.627303  0.796117  0.067401  0.014578  0.008959  0.443167   \n",
       "4   earnings,2011  0.785758  0.725355  0.112005  0.904701  0.088229  0.141651   \n",
       "5   earnings,2012  0.778061  0.262423  0.553152  0.128754  0.141317  0.369947   \n",
       "6   earnings,2013  0.861655  0.774735  0.162517  0.193070  0.657653  0.415445   \n",
       "7   earnings,2014  0.692685  0.261713  0.858547  0.194765  0.469335  0.312604   \n",
       "8   earnings,2015  0.773848  0.221365  0.059592  0.821078  0.796786  0.707739   \n",
       "9   earnings,2016  0.480126  0.630262  0.110059  0.415929  0.924498  0.900963   \n",
       "10  earnings,2017  0.095681  0.515495  0.121555  0.022884  0.468618  0.123357   \n",
       "11  earnings,2018  0.919275  0.719239  0.565170  0.158467  0.971019  0.574890   \n",
       "12  earnings,2019  0.612681  0.111441  0.222512  0.061045  0.329555  0.875114   \n",
       "13  earnings,2020  0.545321  0.376536  0.094252  0.834384  0.336437  0.000992   \n",
       "\n",
       "      beta_7    beta_8    beta_9   beta_10   beta_11   beta_12   beta_13  \n",
       "0   0.924750  0.822374  0.009066  0.000138  0.004734  0.035255  0.371528  \n",
       "1   0.556308  0.032916  0.097723  0.622187  0.686393  0.223144  0.166409  \n",
       "2   0.244617  0.763030  0.730143  0.495467  0.396012  0.640606  0.634014  \n",
       "3   0.157330  0.813167  0.906292  0.216099  0.688191  0.806911  0.512133  \n",
       "4   0.265979  0.845823  0.157271  0.988670  0.207667  0.224546  0.448043  \n",
       "5   0.463240  0.506434  0.409626  0.025882  0.773260  0.328180  0.003935  \n",
       "6   0.050021  0.341824  0.277262  0.091713  0.212074  0.081001  0.098619  \n",
       "7   0.085723  0.776779  0.891051  0.632566  0.324320  0.882908  0.220307  \n",
       "8   0.712806  0.800173  0.455333  0.596580  0.390166  0.570340  0.645281  \n",
       "9   0.046638  0.863978  0.640095  0.932071  0.518778  0.894858  0.853393  \n",
       "10  0.188788  0.130608  0.993442  0.942238  0.988921  0.525361  0.486641  \n",
       "11  0.335132  0.568290  0.032843  0.704058  0.034816  0.268424  0.932823  \n",
       "12  0.925385  0.979428  0.486696  0.653518  0.013244  0.144962  0.117658  \n",
       "13  0.359016  0.371424  0.668957  0.812787  0.962868  0.257909  0.341384  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize a dataframe with 13 years of pvalue\n",
    "linreg_tsdf = pd.DataFrame(data = np.zeros([len(list(range(2008,2021)))+1,14]),columns=['variablename','beta_1','beta_2','beta_3','beta_4','beta_5','beta_6','beta_7','beta_8','beta_9','beta_10','beta_11','beta_12','beta_13'])\n",
    "linreg_tsdf.iloc[0,0] = 'Constant'\n",
    "for i in range(4,17):\n",
    "    linreg_tsdf.iloc[i-3,0] = variable[-6]+','+str(year[i])\n",
    "#iterate over years from year 2008 to 2020: (2008 corresponds to 4th column of stdvalue and 2020 corresponds to 17th column of stdvalue)\n",
    "for i in range(4,17):    \n",
    "    #compute all regression using initialized function for xmat and yvec \n",
    "    yvec,xmat = Initializationtsyearunempearningonly(i)\n",
    "    resultsvec = sm.OLS(yvec,xmat).fit()\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    linreg_tsdf.iloc[:,i-3] = resultsvec.pvalues\n",
    "\n",
    "#show the result\n",
    "linreg_tsdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d415d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ebd1109",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 71)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here Initialize the xmatrix and ymatrix for such model as a function. The function is for year i of the unemployment and\n",
    "#it is regressed with all time series of x variables. \n",
    "def Initializationtsyear(i,timelength):\n",
    "    yvec = np.zeros([len(authoritynames),1])\n",
    "    for j in range(len(authoritynames)):\n",
    "            #only take 2008 data onwards\n",
    "            yvec[j,:] = std_values[authoritynames[j]].iloc[4,i]\n",
    "\n",
    "    xmat = np.zeros([len(authoritynames),(timelength+1)*len(xvariable)+1])\n",
    "\n",
    "    xmat[:,0] = 1\n",
    "    for k in range(len(xvariable)):\n",
    "        for j in range(len(authoritynames)):\n",
    "            #only take 2008 data onwards\n",
    "            xmat[j,(timelength+1)*k+1:(timelength+1)*(k+1)+1] = std_values[authoritynames[j]].iloc[xvariable[k],i-timelength:i+1]\n",
    "            \n",
    "            \n",
    "\n",
    "    return yvec, xmat\n",
    "\n",
    "\n",
    "Initializationtsyear(7,4)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56cb1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define time length\n",
    "timelength=4\n",
    "\n",
    "#Initialize a dataframe with 13 years of pvalue\n",
    "linreg_tsdf = pd.DataFrame(data = np.zeros([len(list(range(2012,2021)))*len(xvariable)+1,6]),columns=['variablename','lag=4','lag=3','lag=2','lag=1','lag=0'])\n",
    "linreg_tsdf.iloc[0,0] = 'Constant'\n",
    "\n",
    "#Initialize a dataframe with 13 years of pvalue\n",
    "linreg_tsdfpval = pd.DataFrame(data = np.zeros([len(list(range(2012,2021)))*len(xvariable)+1,6]),columns=['variablename','lag=4','lag=3','lag=2','lag=1','lag=0'])\n",
    "linreg_tsdfpval.iloc[0,0] = 'Constant'\n",
    "\n",
    "#initialize a residual matrix for use of spatial regression \n",
    "#ymat = np.zeros([205,9])\n",
    "#beta_mat = np.zeros([9*timelength+1,])\n",
    "Residual_mat = np.zeros([205,9])\n",
    "\n",
    "for varind in range(len(xvariable)):\n",
    "    for i in range(8,17):\n",
    "        linreg_tsdf.iloc[varind*9+i-7,0] = 'Unemployment'+','+str(year[i])+', with respect to '+ variable[xvariable[varind]]\n",
    "        linreg_tsdfpval.iloc[varind*9+i-7,0] = 'Unemployment'+','+str(year[i])+', with respect to '+ variable[xvariable[varind]]\n",
    "\n",
    "        \n",
    "     \n",
    "#iterate over years from year 2012 to 2020: (2012 corresponds to 8th column of stdvalue and 2020 corresponds to 17th column of stdvalue)\n",
    "for i in range(8,17):    \n",
    "    #compute all regression using initialized function for xmat and yvec, starting from 2013\n",
    "    yvec,xmat = Initializationtsyear(i,timelength)\n",
    "    resultsvec = sm.OLS(yvec,xmat).fit()\n",
    "    linreg_tsdf.iloc[0,5] = resultsvec.params[0]\n",
    "    linreg_tsdfpval.iloc[0,5]=resultsvec.pvalues[0]\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    for varind in range(len(xvariable)):\n",
    "        for timeind in range(timelength+1):\n",
    "            linreg_tsdf.iloc[varind*9+i-7,timeind+1] = resultsvec.params[varind*(timelength+1)+1+timeind]\n",
    "            linreg_tsdfpval.iloc[varind*9+i-7,timeind+1]=resultsvec.pvalues[varind*(timelength+1)+1+timeind]\n",
    "            \n",
    "    #in addition, we also save the residual in a huge Residual matrix\n",
    "    Residual_mat[:,i-8] = np.reshape(yvec - xmat@np.reshape(resultsvec.params,[71,1]),[205])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "861f0b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>lag=4</th>\n",
       "      <th>lag=3</th>\n",
       "      <th>lag=2</th>\n",
       "      <th>lag=1</th>\n",
       "      <th>lag=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.063819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment,2012, with respect to Economic ac...</td>\n",
       "      <td>-0.024020</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.014998</td>\n",
       "      <td>-0.046129</td>\n",
       "      <td>0.152611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unemployment,2013, with respect to Economic ac...</td>\n",
       "      <td>0.087247</td>\n",
       "      <td>-0.065630</td>\n",
       "      <td>0.071807</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.038424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unemployment,2014, with respect to Economic ac...</td>\n",
       "      <td>0.115908</td>\n",
       "      <td>-0.040349</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>-0.040274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment,2015, with respect to Economic ac...</td>\n",
       "      <td>0.052930</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>-0.060664</td>\n",
       "      <td>0.083576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Unemployment,2016, with respect to population_...</td>\n",
       "      <td>-0.293637</td>\n",
       "      <td>0.443143</td>\n",
       "      <td>-0.799287</td>\n",
       "      <td>1.144637</td>\n",
       "      <td>-0.705318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Unemployment,2017, with respect to population_...</td>\n",
       "      <td>0.346879</td>\n",
       "      <td>-0.637994</td>\n",
       "      <td>0.535774</td>\n",
       "      <td>0.188480</td>\n",
       "      <td>-0.483141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Unemployment,2018, with respect to population_...</td>\n",
       "      <td>-0.560459</td>\n",
       "      <td>1.067732</td>\n",
       "      <td>-0.449611</td>\n",
       "      <td>0.058287</td>\n",
       "      <td>-0.108603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Unemployment,2019, with respect to population_...</td>\n",
       "      <td>-0.210105</td>\n",
       "      <td>-0.242317</td>\n",
       "      <td>0.752134</td>\n",
       "      <td>-0.333991</td>\n",
       "      <td>-0.038007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Unemployment,2020, with respect to population_...</td>\n",
       "      <td>0.472067</td>\n",
       "      <td>-0.343592</td>\n",
       "      <td>-0.088119</td>\n",
       "      <td>-0.097686</td>\n",
       "      <td>0.159418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          variablename     lag=4     lag=3  \\\n",
       "0                                             Constant  0.000000  0.000000   \n",
       "1    Unemployment,2012, with respect to Economic ac... -0.024020 -0.000708   \n",
       "2    Unemployment,2013, with respect to Economic ac...  0.087247 -0.065630   \n",
       "3    Unemployment,2014, with respect to Economic ac...  0.115908 -0.040349   \n",
       "4    Unemployment,2015, with respect to Economic ac...  0.052930  0.025419   \n",
       "..                                                 ...       ...       ...   \n",
       "122  Unemployment,2016, with respect to population_... -0.293637  0.443143   \n",
       "123  Unemployment,2017, with respect to population_...  0.346879 -0.637994   \n",
       "124  Unemployment,2018, with respect to population_... -0.560459  1.067732   \n",
       "125  Unemployment,2019, with respect to population_... -0.210105 -0.242317   \n",
       "126  Unemployment,2020, with respect to population_...  0.472067 -0.343592   \n",
       "\n",
       "        lag=2     lag=1     lag=0  \n",
       "0    0.000000  0.000000 -0.063819  \n",
       "1   -0.014998 -0.046129  0.152611  \n",
       "2    0.071807  0.035595  0.038424  \n",
       "3    0.000512  0.063990 -0.040274  \n",
       "4   -0.014129 -0.060664  0.083576  \n",
       "..        ...       ...       ...  \n",
       "122 -0.799287  1.144637 -0.705318  \n",
       "123  0.535774  0.188480 -0.483141  \n",
       "124 -0.449611  0.058287 -0.108603  \n",
       "125  0.752134 -0.333991 -0.038007  \n",
       "126 -0.088119 -0.097686  0.159418  \n",
       "\n",
       "[127 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we return the coefficient for betas for earning variables:\n",
    "linreg_tsdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a12b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>lag=4</th>\n",
       "      <th>lag=3</th>\n",
       "      <th>lag=2</th>\n",
       "      <th>lag=1</th>\n",
       "      <th>lag=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Unemployment,2012, with respect to earnings</td>\n",
       "      <td>-0.055705</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>-0.257204</td>\n",
       "      <td>0.131217</td>\n",
       "      <td>-0.103704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Unemployment,2013, with respect to earnings</td>\n",
       "      <td>-0.114578</td>\n",
       "      <td>-0.125823</td>\n",
       "      <td>-0.196009</td>\n",
       "      <td>-0.249700</td>\n",
       "      <td>0.043393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Unemployment,2014, with respect to earnings</td>\n",
       "      <td>-0.177718</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>-0.090242</td>\n",
       "      <td>-0.227534</td>\n",
       "      <td>-0.148128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Unemployment,2015, with respect to earnings</td>\n",
       "      <td>-0.051972</td>\n",
       "      <td>0.117874</td>\n",
       "      <td>-0.141386</td>\n",
       "      <td>-0.109377</td>\n",
       "      <td>0.027613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Unemployment,2016, with respect to earnings</td>\n",
       "      <td>-0.206746</td>\n",
       "      <td>-0.124327</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.063936</td>\n",
       "      <td>0.258437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Unemployment,2017, with respect to earnings</td>\n",
       "      <td>0.097770</td>\n",
       "      <td>-0.071616</td>\n",
       "      <td>-0.064650</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>0.075157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Unemployment,2018, with respect to earnings</td>\n",
       "      <td>-0.053587</td>\n",
       "      <td>0.193979</td>\n",
       "      <td>-0.069417</td>\n",
       "      <td>0.056417</td>\n",
       "      <td>-0.202651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Unemployment,2019, with respect to earnings</td>\n",
       "      <td>-0.112162</td>\n",
       "      <td>0.215944</td>\n",
       "      <td>-0.296737</td>\n",
       "      <td>-0.153584</td>\n",
       "      <td>-0.066567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Unemployment,2020, with respect to earnings</td>\n",
       "      <td>0.102429</td>\n",
       "      <td>-0.322723</td>\n",
       "      <td>0.040586</td>\n",
       "      <td>-0.147464</td>\n",
       "      <td>-0.090571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variablename     lag=4     lag=3  \\\n",
       "109  Unemployment,2012, with respect to earnings -0.055705  0.109658   \n",
       "110  Unemployment,2013, with respect to earnings -0.114578 -0.125823   \n",
       "111  Unemployment,2014, with respect to earnings -0.177718  0.026219   \n",
       "112  Unemployment,2015, with respect to earnings -0.051972  0.117874   \n",
       "113  Unemployment,2016, with respect to earnings -0.206746 -0.124327   \n",
       "114  Unemployment,2017, with respect to earnings  0.097770 -0.071616   \n",
       "115  Unemployment,2018, with respect to earnings -0.053587  0.193979   \n",
       "116  Unemployment,2019, with respect to earnings -0.112162  0.215944   \n",
       "117  Unemployment,2020, with respect to earnings  0.102429 -0.322723   \n",
       "\n",
       "        lag=2     lag=1     lag=0  \n",
       "109 -0.257204  0.131217 -0.103704  \n",
       "110 -0.196009 -0.249700  0.043393  \n",
       "111 -0.090242 -0.227534 -0.148128  \n",
       "112 -0.141386 -0.109377  0.027613  \n",
       "113  0.037962  0.063936  0.258437  \n",
       "114 -0.064650 -0.032652  0.075157  \n",
       "115 -0.069417  0.056417 -0.202651  \n",
       "116 -0.296737 -0.153584 -0.066567  \n",
       "117  0.040586 -0.147464 -0.090571  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we return the pvalue for betas for earning variables:\n",
    "linreg_tsdf[109:118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "630970cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>lag=4</th>\n",
       "      <th>lag=3</th>\n",
       "      <th>lag=2</th>\n",
       "      <th>lag=1</th>\n",
       "      <th>lag=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Unemployment,2012, with respect to earnings</td>\n",
       "      <td>0.535637</td>\n",
       "      <td>0.416281</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>0.329281</td>\n",
       "      <td>0.479081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Unemployment,2013, with respect to earnings</td>\n",
       "      <td>0.400209</td>\n",
       "      <td>0.415567</td>\n",
       "      <td>0.199345</td>\n",
       "      <td>0.147870</td>\n",
       "      <td>0.788132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Unemployment,2014, with respect to earnings</td>\n",
       "      <td>0.144964</td>\n",
       "      <td>0.831631</td>\n",
       "      <td>0.524864</td>\n",
       "      <td>0.077020</td>\n",
       "      <td>0.337430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Unemployment,2015, with respect to earnings</td>\n",
       "      <td>0.653257</td>\n",
       "      <td>0.388932</td>\n",
       "      <td>0.242570</td>\n",
       "      <td>0.460702</td>\n",
       "      <td>0.836669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Unemployment,2016, with respect to earnings</td>\n",
       "      <td>0.145667</td>\n",
       "      <td>0.353469</td>\n",
       "      <td>0.823771</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>0.065350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Unemployment,2017, with respect to earnings</td>\n",
       "      <td>0.492523</td>\n",
       "      <td>0.675638</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.839876</td>\n",
       "      <td>0.634255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Unemployment,2018, with respect to earnings</td>\n",
       "      <td>0.714524</td>\n",
       "      <td>0.180861</td>\n",
       "      <td>0.625970</td>\n",
       "      <td>0.705321</td>\n",
       "      <td>0.068086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Unemployment,2019, with respect to earnings</td>\n",
       "      <td>0.430857</td>\n",
       "      <td>0.122879</td>\n",
       "      <td>0.038155</td>\n",
       "      <td>0.184728</td>\n",
       "      <td>0.399852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Unemployment,2020, with respect to earnings</td>\n",
       "      <td>0.550426</td>\n",
       "      <td>0.075327</td>\n",
       "      <td>0.783322</td>\n",
       "      <td>0.157460</td>\n",
       "      <td>0.365524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variablename     lag=4     lag=3  \\\n",
       "109  Unemployment,2012, with respect to earnings  0.535637  0.416281   \n",
       "110  Unemployment,2013, with respect to earnings  0.400209  0.415567   \n",
       "111  Unemployment,2014, with respect to earnings  0.144964  0.831631   \n",
       "112  Unemployment,2015, with respect to earnings  0.653257  0.388932   \n",
       "113  Unemployment,2016, with respect to earnings  0.145667  0.353469   \n",
       "114  Unemployment,2017, with respect to earnings  0.492523  0.675638   \n",
       "115  Unemployment,2018, with respect to earnings  0.714524  0.180861   \n",
       "116  Unemployment,2019, with respect to earnings  0.430857  0.122879   \n",
       "117  Unemployment,2020, with respect to earnings  0.550426  0.075327   \n",
       "\n",
       "        lag=2     lag=1     lag=0  \n",
       "109  0.053406  0.329281  0.479081  \n",
       "110  0.199345  0.147870  0.788132  \n",
       "111  0.524864  0.077020  0.337430  \n",
       "112  0.242570  0.460702  0.836669  \n",
       "113  0.823771  0.676845  0.065350  \n",
       "114  0.677143  0.839876  0.634255  \n",
       "115  0.625970  0.705321  0.068086  \n",
       "116  0.038155  0.184728  0.399852  \n",
       "117  0.783322  0.157460  0.365524  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_tsdfpval[109:118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de50966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3f6ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable % all in employment who are - 3: associate prof & tech occupations (SOC2010) has the greatest number of significant values, 5.0 in particular\n"
     ]
    }
   ],
   "source": [
    "#Get the variable with number of significant values\n",
    "sigindex = np.zeros(14)\n",
    "for i in range(1,127):\n",
    "    for j in range(5):\n",
    "        if linreg_tsdfpval.iloc[i,j+1]<0.05:\n",
    "            sigindex[(i-1)//9]+=1\n",
    "#find the variable with the greatest number of significant values\n",
    "np.argmax(sigindex)\n",
    "\n",
    "print(f'variable {variable[xvariable[np.argmax(sigindex)]]} has the greatest number of significant values, {np.max(sigindex)} in particular')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f6afe",
   "metadata": {},
   "source": [
    "# Spatial Regression and Moran's I\n",
    "\n",
    "\n",
    "Spatial regression:\n",
    "$Y_i = \\alpha+X\\beta +WX\\gamma +\\epsilon$\n",
    "\n",
    "\n",
    "\n",
    "Create weight matrix: A common approach is to give a weight of 1 if two zones are neighbors, and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbc90136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#weight calculation:\n",
    "import geopandas as gpd\n",
    "\n",
    "# open file\n",
    "authorityshp = gpd.read_file('CTYUA_DEC_2021_UK_BFC.shp')\n",
    "\n",
    "\n",
    "# add NEIGHBORS column\n",
    "authorityshp[\"NEIGHBORS\"] = None  \n",
    "\n",
    "for index, authority in authorityshp.iterrows():   \n",
    "\n",
    "    # get 'not disjoint' countries\n",
    "    neighbors = authorityshp[~authorityshp.geometry.disjoint(authority.geometry)].CTYUA21NM.tolist()\n",
    "\n",
    "    # remove own name of the authority from the list\n",
    "    neighbors = [ name for name in neighbors if authority.CTYUA21NM != name ]\n",
    "\n",
    "    # add names of neighbors as NEIGHBORS value\n",
    "    authorityshp.at[index, \"NEIGHBORS\"] = \", \".join(neighbors)\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7dc9520f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Hartlepool\n",
       "1             Middlesbrough\n",
       "2      Redcar and Cleveland\n",
       "3          Stockton-on-Tees\n",
       "4                Darlington\n",
       "               ...         \n",
       "212                 Torfaen\n",
       "213           Monmouthshire\n",
       "214                 Newport\n",
       "215                   Powys\n",
       "216          Merthyr Tydfil\n",
       "Name: CTYUA21NM, Length: 217, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorityshp[\"CTYUA21NM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b285e5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        Stockton-on-Tees, County Durham\n",
       "1      Redcar and Cleveland, Stockton-on-Tees, North ...\n",
       "2                         Middlesbrough, North Yorkshire\n",
       "3      Hartlepool, Middlesbrough, Darlington, County ...\n",
       "4       Stockton-on-Tees, County Durham, North Yorkshire\n",
       "                             ...                        \n",
       "212    Caerphilly, Blaenau Gwent, Monmouthshire, Newport\n",
       "213    Herefordshire, County of, Gloucestershire, Bla...\n",
       "214          Cardiff, Caerphilly, Torfaen, Monmouthshire\n",
       "215    Herefordshire, County of, Shropshire, Gwynedd,...\n",
       "216                 Rhondda Cynon Taf, Caerphilly, Powys\n",
       "Name: NEIGHBORS, Length: 217, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The neighbors \n",
    "authorityshp[\"NEIGHBORS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce396b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize the authority so that it has the same authority order with the initial dataset\n",
    "organizeddf = pd.DataFrame(data = np.zeros([len(authoritynames),2]),columns=['authorityname','neighbors'])\n",
    "#the first column of organzed dataframe is the authoritynames in order\n",
    "organizeddf.iloc[:,0] = authoritynames\n",
    "for i in range(len(authoritynames)):\n",
    "    for j in range(len(authorityshp[\"CTYUA21NM\"])):\n",
    "        #if the j th authorityshp's name is the ith authoritynames\n",
    "        if authoritynames[i] == authorityshp[\"CTYUA21NM\"][j]:\n",
    "            #get the neighbor value\n",
    "            organizeddf.iloc[i,1] = authorityshp[\"NEIGHBORS\"][j]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8b5f6",
   "metadata": {},
   "source": [
    "By organizing the authority and their corresponding neighbors in original order, it is much easier to compute weight matrix. Here check the neighbors matrix and see if there is any NA values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ef419fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorityname</th>\n",
       "      <th>neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Darlington</td>\n",
       "      <td>Stockton-on-Tees, County Durham, North Yorkshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>County Durham</td>\n",
       "      <td>Hartlepool, Stockton-on-Tees, Darlington, Nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>Stockton-on-Tees, County Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Redcar and Cleveland, Stockton-on-Tees, North ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Northumberland</td>\n",
       "      <td>County Durham, Newcastle upon Tyne, North Tyne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>South Ayrshire</td>\n",
       "      <td>Dumfries and Galloway, East Ayrshire, North Ay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>South Lanarkshire</td>\n",
       "      <td>Dumfries and Galloway, East Ayrshire, East Ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Stirling</td>\n",
       "      <td>Clackmannanshire, Falkirk, Argyll and Bute, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>West Dunbartonshire</td>\n",
       "      <td>Stirling, Argyll and Bute, East Dunbartonshire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>West Lothian</td>\n",
       "      <td>Falkirk, Scottish Borders, South Lanarkshire, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           authorityname                                          neighbors\n",
       "0             Darlington   Stockton-on-Tees, County Durham, North Yorkshire\n",
       "1          County Durham  Hartlepool, Stockton-on-Tees, Darlington, Nort...\n",
       "2             Hartlepool                    Stockton-on-Tees, County Durham\n",
       "3          Middlesbrough  Redcar and Cleveland, Stockton-on-Tees, North ...\n",
       "4         Northumberland  County Durham, Newcastle upon Tyne, North Tyne...\n",
       "..                   ...                                                ...\n",
       "200       South Ayrshire  Dumfries and Galloway, East Ayrshire, North Ay...\n",
       "201    South Lanarkshire  Dumfries and Galloway, East Ayrshire, East Ren...\n",
       "202             Stirling  Clackmannanshire, Falkirk, Argyll and Bute, We...\n",
       "203  West Dunbartonshire  Stirling, Argyll and Bute, East Dunbartonshire...\n",
       "204         West Lothian  Falkirk, Scottish Borders, South Lanarkshire, ...\n",
       "\n",
       "[205 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organizeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccca8238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there is any NA number in the organized dataframe\n",
    "organizeddf['neighbors'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a558f",
   "metadata": {},
   "source": [
    "Now we can compute the weight matrix. This can be done by finding the corresponding neighbor and return 1 if the entry i j, corresponding to the ith authority and jth authority are neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c2f58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      "  0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      "  1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      "  1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      "  0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      "  1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      "  0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      "  1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      "  0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1.\n",
      "  1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      "  1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      "  1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      "  1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      "  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      "  1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      "  0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#develop a weight matrix \n",
    "weightmat = np.zeros([len(authoritynames),len(authoritynames)])\n",
    "\n",
    "for i in range(len(organizeddf[\"authorityname\"])):\n",
    "    #ignore the case when the neighbors is a float number 0.0. In which case, it does not have neighbors\n",
    "    if organizeddf[\"neighbors\"][i]==0:\n",
    "        pass\n",
    "    else:\n",
    "        #split \n",
    "        splitneighbors = organizeddf[\"neighbors\"][i].split(\", \")\n",
    "        for neighborname in splitneighbors:\n",
    "            for j in range(len(organizeddf[\"authorityname\"])):\n",
    "                    #if neighborname is the same as the jth authorityname\n",
    "                    if neighborname == organizeddf[\"authorityname\"][j]:\n",
    "                        #it will be 1\n",
    "                        weightmat[i,j] = 1\n",
    "\n",
    "#display the whole matrix\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(weightmat)\n",
    "np.set_printoptions(threshold = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d732c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [6, 1, 40], 1: [2, 6, 0, 4, 11, 7, 18, 40], 2: [6, 1], 3: [5, 6, 40], 4: [1, 8, 9, 7, 18, 198], 5: [3, 40], 6: [2, 3, 0, 1, 40], 7: [1, 4, 10, 11], 8: [4, 9], 9: [4, 8], 10: [11, 7], 11: [1, 10, 7], 12: [19, 20, 29], 13: [29], 14: [17, 15, 61, 21, 25, 27, 54, 64], 15: [16, 17, 14, 61, 34, 155, 156], 16: [17, 15, 30, 31, 33], 17: [16, 14, 15, 24, 27, 28, 33], 18: [1, 4, 29, 40, 178, 198], 19: [12, 20, 24, 28, 29], 20: [12, 19, 21, 23, 24, 29], 21: [14, 20, 22, 23, 24, 25, 26, 27], 22: [21, 23, 26, 46, 47, 54], 23: [20, 21, 22, 46, 29], 24: [17, 19, 20, 21, 27, 28], 25: [14, 21, 26, 54], 26: [21, 22, 25, 54], 27: [17, 14, 21, 24], 28: [17, 19, 24, 33, 29], 29: [12, 13, 19, 20, 23, 28, 30, 33, 32, 45, 46, 18, 40], 30: [16, 31, 33, 32, 29], 31: [16, 30, 32], 32: [30, 31, 29], 33: [16, 17, 28, 30, 29], 34: [15], 35: [38, 39, 42, 40], 36: [35], 37: [38, 56], 38: [35, 37, 42, 56, 57], 39: [35, 40], 40: [3, 5, 6, 0, 35, 39, 1, 42, 45, 48, 49, 18, 29], 41: [42, 43, 44, 47, 49, 54], 42: [35, 38, 41, 43, 49, 40, 57], 43: [41, 42, 44, 54, 57], 44: [41, 43, 54], 45: [46, 47, 48, 29, 40], 46: [22, 23, 45, 47, 29], 47: [22, 41, 45, 46, 48, 49, 54], 48: [45, 47, 49, 40], 49: [41, 42, 47, 48, 40], 50: [54], 51: [55], 52: [57], 53: [58, 55, 56], 54: [50, 14, 22, 25, 26, 41, 43, 44, 47, 55, 57, 64], 55: [51, 53, 58, 59, 54, 56, 57, 64, 65], 56: [37, 38, 53, 77, 58, 80, 55, 83, 57], 57: [38, 52, 42, 43, 54, 55, 56], 58: [53, 77, 122, 74, 59, 80, 55, 56], 59: [122, 130, 58, 55, 134, 65], 60: [61, 149, 73, 171, 157], 61: [63, 14, 15, 64, 73, 156, 157], 62: [64], 63: [61, 64], 64: [63, 62, 14, 61, 66, 68, 71, 72, 54, 55, 65, 73], 65: [59, 66, 67, 70, 149, 55, 134, 64, 73], 66: [68, 69, 70, 71, 64, 65, 73], 67: [70, 65], 68: [66, 69, 72, 64, 73], 69: [66, 68, 71, 72], 70: [66, 67, 65, 73], 71: [66, 69, 72, 64], 72: [68, 69, 71, 64], 73: [61, 66, 68, 70, 149, 64, 65], 74: [122, 75, 58, 80], 75: [76, 122, 74, 130, 80, 82], 76: [75, 82], 77: [58, 80, 56], 78: [81], 79: [109, 81], 80: [77, 74, 75, 58, 81, 82, 56, 83, 84], 81: [78, 79, 106, 109, 114, 117, 80, 82, 84], 82: [76, 75, 130, 100, 106, 108, 110, 80, 81], 83: [80, 56, 84], 84: [80, 81, 83], 85: [86, 100, 102, 89, 90, 98], 86: [85, 87, 90, 95, 96, 98], 87: [86, 89, 90, 94, 96, 117], 88: [102, 105, 111, 91], 89: [100, 85, 106, 87, 90, 117], 90: [86, 85, 87, 89], 91: [102, 88, 98], 92: [103, 104, 113, 95, 97], 93: [103, 107, 95], 94: [99, 87, 114, 96, 117], 95: [86, 103, 92, 93], 96: [86, 87, 94], 97: [112, 92, 113, 115], 98: [86, 102, 85, 91], 99: [109, 94, 114], 100: [102, 85, 106, 89, 108, 82], 101: [103, 107, 133], 102: [100, 85, 105, 88, 108, 91, 98], 103: [101, 104, 107, 92, 93, 95, 133, 135], 104: [103, 92, 113, 116, 135], 105: [102, 88, 108, 110, 111], 106: [100, 89, 117, 81, 82], 107: [101, 103, 93], 108: [100, 102, 105, 110, 82], 109: [79, 99, 114, 81], 110: [125, 130, 105, 108, 111, 82, 135], 111: [105, 88, 110, 115, 135], 112: [113, 115, 116, 97, 135], 113: [104, 112, 92, 116, 97], 114: [99, 109, 94, 117, 81], 115: [111, 112, 97, 135], 116: [104, 112, 113, 135], 117: [106, 87, 89, 94, 114, 81], 118: [128, 129, 132, 135], 119: [131, 136], 120: [], 121: [133], 122: [74, 75, 130, 58, 59], 123: [132], 124: [127, 129, 134], 125: [128, 130, 110, 135], 126: [132], 127: [124, 129, 146, 132, 134], 128: [118, 125, 129, 130, 135], 129: [118, 127, 124, 128, 130, 132, 134], 130: [125, 128, 129, 122, 75, 59, 110, 82, 134], 131: [119, 133, 135, 136], 132: [118, 127, 129, 123, 126, 146, 148, 135, 136], 133: [121, 101, 103, 131, 135], 134: [144, 127, 124, 129, 146, 130, 59, 149, 65], 135: [118, 125, 128, 103, 104, 110, 111, 112, 115, 116, 131, 132, 133, 136], 136: [119, 131, 132, 135], 137: [140, 143, 146, 150], 138: [137, 140, 143], 139: [147], 140: [137, 150], 141: [147], 142: [148, 132], 143: [137, 146, 149], 144: [146, 149, 134], 145: [147], 146: [137, 143, 144, 127, 148, 149, 132, 134, 150], 147: [141, 145, 139, 148, 150], 148: [146, 147, 132, 150], 149: [143, 144, 146, 134, 65, 73, 171], 150: [137, 140, 146, 148, 147], 151: [], 152: [153, 154, 157], 153: [152, 154], 154: [152, 153, 155, 156, 157], 155: [15, 154, 156], 156: [15, 61, 154, 155, 157], 157: [61, 152, 154, 156, 158, 160, 162, 168, 169, 171, 167], 158: [159, 160, 157], 159: [158, 160], 160: [158, 159, 161, 162, 157], 161: [160, 162], 162: [160, 161, 163, 157], 163: [162, 164], 164: [163, 165], 165: [164, 168, 172], 166: [], 167: [168, 157], 168: [165, 169, 170, 172, 157, 167], 169: [168, 170, 171, 157], 170: [168, 169, 171, 172], 171: [149, 169, 170, 172, 157], 172: [165, 168, 170, 171], 173: [174], 174: [189, 192, 173, 175, 196], 175: [174, 179, 196], 176: [189, 202, 203, 196], 177: [202, 187, 196], 178: [18, 180, 198, 200, 201], 179: [175, 196], 180: [178, 183, 193, 200, 201], 181: [202, 203, 188, 194], 182: [191, 198, 184], 183: [180, 193, 201, 197, 188], 184: [182, 191, 198, 204], 185: [], 186: [202, 204, 194], 187: [177, 196], 188: [183, 201, 197, 203, 181, 194], 189: [192, 174, 176, 196], 190: [193, 197], 191: [182, 198, 184], 192: [189, 174], 193: [180, 183, 190, 200, 197], 194: [186, 201, 202, 204, 181, 188], 195: [], 196: [177, 189, 202, 174, 176, 175, 179, 187], 197: [183, 190, 193, 188], 198: [4, 18, 178, 182, 191, 201, 184, 204], 199: [], 200: [178, 180, 193], 201: [178, 180, 183, 198, 204, 188, 194], 202: [177, 186, 176, 203, 181, 196, 194], 203: [202, 176, 181, 188], 204: [186, 198, 201, 184, 194]}\n"
     ]
    }
   ],
   "source": [
    "#develop a weight dictionary for Moran's I \n",
    "weightdict = {}\n",
    "\n",
    "for i in range(len(organizeddf[\"authorityname\"])):\n",
    "    #initialize weightdict[i] with an empty value\n",
    "    weightdict[i] = []\n",
    "    #ignore the case when the neighbors is a float number 0.0. In which case, it does not have neighbors\n",
    "    if organizeddf[\"neighbors\"][i]==0:\n",
    "        pass\n",
    "    else:\n",
    "        #split \n",
    "        splitneighbors = organizeddf[\"neighbors\"][i].split(\", \")\n",
    "        for neighborname in splitneighbors:\n",
    "            for j in range(len(organizeddf[\"authorityname\"])):\n",
    "                    #if neighborname is the same as the jth authorityname\n",
    "                    if neighborname == organizeddf[\"authorityname\"][j]:\n",
    "                        #it will be 1\n",
    "                        weightdict[i] = weightdict[i]+[j]\n",
    "print(weightdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d16c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import W\n",
    "weightmoran = W(weightdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a9ad2",
   "metadata": {},
   "source": [
    "## Moran's I \n",
    "\n",
    "Here we compute Moran's I first to check if spatial regression is needed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f712976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get Ymat for all Unemployment datas for years from 2008 onwards\n",
    "Ymat = np.zeros([len(authoritynames),13])\n",
    "for j in range(len(authoritynames)):\n",
    "        #take 2008 data onwards\n",
    "        Ymat[j,:] = std_values[authoritynames[j]].iloc[4,4:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14622d9e",
   "metadata": {},
   "source": [
    "Here I compute Morans' I for all unemployment from 2008 to 2020 with consideration of all time series of wage and other conditional variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f6250e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARNING: ', 120, ' is an island (no neighbors)')\n",
      "('WARNING: ', 151, ' is an island (no neighbors)')\n",
      "('WARNING: ', 166, ' is an island (no neighbors)')\n",
      "('WARNING: ', 185, ' is an island (no neighbors)')\n",
      "('WARNING: ', 195, ' is an island (no neighbors)')\n",
      "('WARNING: ', 199, ' is an island (no neighbors)')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Observed I</th>\n",
       "      <th>Expected I</th>\n",
       "      <th>p-value</th>\n",
       "      <th>standard error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.118205</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>7.099537e-03</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.241198</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>4.741041e-07</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>2.934892e-01</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>4.520926e-01</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.099867</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>1.844822e-02</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>-0.003402</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>4.880795e-01</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>3.494320e-01</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>2.918227e-02</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.112644</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>9.605445e-03</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>-0.007094</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>4.825899e-01</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.090755</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>2.836343e-02</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>1.361039e-02</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.068420</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>7.207554e-02</td>\n",
       "      <td>0.050203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Observed I  Expected I       p-value  standard error\n",
       "0   2008    0.118205   -0.004902  7.099537e-03        0.050203\n",
       "1   2009    0.241198   -0.004902  4.741041e-07        0.050203\n",
       "2   2010    0.022369   -0.004902  2.934892e-01        0.050203\n",
       "3   2011    0.001141   -0.004902  4.520926e-01        0.050203\n",
       "4   2012    0.099867   -0.004902  1.844822e-02        0.050203\n",
       "5   2013   -0.003402   -0.004902  4.880795e-01        0.050203\n",
       "6   2014    0.014519   -0.004902  3.494320e-01        0.050203\n",
       "7   2015    0.090130   -0.004902  2.918227e-02        0.050203\n",
       "8   2016    0.112644   -0.004902  9.605445e-03        0.050203\n",
       "9   2017   -0.007094   -0.004902  4.825899e-01        0.050203\n",
       "10  2018    0.090755   -0.004902  2.836343e-02        0.050203\n",
       "11  2019    0.105963   -0.004902  1.361039e-02        0.050203\n",
       "12  2020    0.068420   -0.004902  7.207554e-02        0.050203"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe for storing Moran's I  \n",
    "MoransIdf = pd.DataFrame(data = np.zeros([13,5]),columns=['Year','Observed I','Expected I','p-value','standard error'])\n",
    "MoransIdf.iloc[:,0] = year[4:]\n",
    "for i in range(13):\n",
    "    mi = pysal.explore.esda.Moran(Ymat[:,i]-np.mean(Ymat[:,i]), weightmoran, two_tailed=False)\n",
    "    MoransIdf.iloc[i,1] = mi.I\n",
    "    MoransIdf.iloc[i,2] = mi.EI\n",
    "    MoransIdf.iloc[i,3] = mi.p_norm\n",
    "    MoransIdf.iloc[i,4] = mi.seI_norm\n",
    "\n",
    "MoransIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b97f72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, \"Moran's I\")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot()\n",
    "plt.errorbar(MoransIdf.iloc[:,0], MoransIdf.iloc[:,1], yerr = MoransIdf.iloc[:,4],fmt = 'o',color = 'black', \n",
    "            ecolor = 'orange', capsize=3)\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Moran's I\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebd6de",
   "metadata": {},
   "source": [
    "# Spatial Regression \n",
    "\n",
    "With the weight of authorities, we can compute spatial regression as following:\n",
    "\n",
    "Since the spatial regression has the form:\n",
    "$$y=Wy \\rho  + X\\beta +\\epsilon$$\n",
    "\n",
    "This can also be cconverted to a matrix form:\n",
    "$$y = \\begin{pmatrix}\n",
    "Wy & X\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "\\rho\\\\\n",
    "\\beta\n",
    "\\end{pmatrix} +\\epsilon$$\n",
    "\n",
    "which is essentially a normal linear regression model but appended with spatial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "165628cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03865806, 0.02350941, 0.01013138, ..., 0.12596295, 0.06899751,\n",
       "       0.00775451])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalueW = np.linalg.eig(weightmat)[0]\n",
    "APLEvec = np.zeros(9)\n",
    "for i in range(9): \n",
    "    upperfrac_b = Residual_mat[:,i].T@((weightmat+weightmat.T)/2)@Residual_mat[:,i]\n",
    "    lowerfrac_A = Residual_mat[:,i].T@(weightmat@weightmat.T-np.outer(eigenvalueW,eigenvalueW)@np.eye(len(eigenvalueW))/len(eigenvalueW))@Residual_mat[:,i]\n",
    "    #APLE = np.linalg.solve(lowerfrac_A,upperfrac_b)\n",
    "    APLEvec[i] = upperfrac_b/lowerfrac_A\n",
    "    np.linalg.norm(APLEvec)\n",
    "APLEvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "937871b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>lag=4</th>\n",
       "      <th>lag=3</th>\n",
       "      <th>lag=2</th>\n",
       "      <th>lag=1</th>\n",
       "      <th>lag=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.051107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment,2012, with respect to Economic ac...</td>\n",
       "      <td>-0.024014</td>\n",
       "      <td>-0.018697</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>-0.051307</td>\n",
       "      <td>0.162037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unemployment,2013, with respect to Economic ac...</td>\n",
       "      <td>0.077695</td>\n",
       "      <td>-0.060861</td>\n",
       "      <td>0.061026</td>\n",
       "      <td>0.040560</td>\n",
       "      <td>0.034958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unemployment,2014, with respect to Economic ac...</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>-0.042662</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.063230</td>\n",
       "      <td>-0.041175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment,2015, with respect to Economic ac...</td>\n",
       "      <td>0.052951</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>-0.072072</td>\n",
       "      <td>0.080038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Unemployment,2016, with respect to population_...</td>\n",
       "      <td>-0.273811</td>\n",
       "      <td>0.451190</td>\n",
       "      <td>-0.832571</td>\n",
       "      <td>1.163501</td>\n",
       "      <td>-0.687128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Unemployment,2017, with respect to population_...</td>\n",
       "      <td>0.354918</td>\n",
       "      <td>-0.696834</td>\n",
       "      <td>0.604189</td>\n",
       "      <td>0.190930</td>\n",
       "      <td>-0.491427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Unemployment,2018, with respect to population_...</td>\n",
       "      <td>-0.947075</td>\n",
       "      <td>1.524471</td>\n",
       "      <td>-0.460169</td>\n",
       "      <td>-0.154350</td>\n",
       "      <td>-0.020484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Unemployment,2019, with respect to population_...</td>\n",
       "      <td>-0.127462</td>\n",
       "      <td>-0.124394</td>\n",
       "      <td>0.810927</td>\n",
       "      <td>-0.832172</td>\n",
       "      <td>0.301385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Unemployment,2020, with respect to population_...</td>\n",
       "      <td>0.459883</td>\n",
       "      <td>-0.315652</td>\n",
       "      <td>-0.131991</td>\n",
       "      <td>-0.078796</td>\n",
       "      <td>0.165480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          variablename     lag=4     lag=3  \\\n",
       "0                                             Constant  0.000000  0.000000   \n",
       "1    Unemployment,2012, with respect to Economic ac... -0.024014 -0.018697   \n",
       "2    Unemployment,2013, with respect to Economic ac...  0.077695 -0.060861   \n",
       "3    Unemployment,2014, with respect to Economic ac...  0.115752 -0.042662   \n",
       "4    Unemployment,2015, with respect to Economic ac...  0.052951  0.018534   \n",
       "..                                                 ...       ...       ...   \n",
       "122  Unemployment,2016, with respect to population_... -0.273811  0.451190   \n",
       "123  Unemployment,2017, with respect to population_...  0.354918 -0.696834   \n",
       "124  Unemployment,2018, with respect to population_... -0.947075  1.524471   \n",
       "125  Unemployment,2019, with respect to population_... -0.127462 -0.124394   \n",
       "126  Unemployment,2020, with respect to population_...  0.459883 -0.315652   \n",
       "\n",
       "        lag=2     lag=1     lag=0  \n",
       "0    0.000000  0.000000 -0.051107  \n",
       "1   -0.007018 -0.051307  0.162037  \n",
       "2    0.061026  0.040560  0.034958  \n",
       "3    0.002058  0.063230 -0.041175  \n",
       "4   -0.001666 -0.072072  0.080038  \n",
       "..        ...       ...       ...  \n",
       "122 -0.832571  1.163501 -0.687128  \n",
       "123  0.604189  0.190930 -0.491427  \n",
       "124 -0.460169 -0.154350 -0.020484  \n",
       "125  0.810927 -0.832172  0.301385  \n",
       "126 -0.131991 -0.078796  0.165480  \n",
       "\n",
       "[127 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the spatial part Wy\n",
    "spatialtemp = weightmat@yvec\n",
    "\n",
    "#Initialize a dataframe with 9 years of coefficient\n",
    "spatlinreg_tsdf = pd.DataFrame(data = np.zeros([len(list(range(2012,2021)))*len(xvariable)+1,6]),columns=['variablename','lag=4','lag=3','lag=2','lag=1','lag=0'])\n",
    "spatlinreg_tsdf.iloc[0,0] = 'Constant'\n",
    "#Initialize a dataframe with 13 years of pvalue\n",
    "spatlinreg_tsdfpval = pd.DataFrame(data = np.zeros([len(list(range(2012,2021)))*len(xvariable)+1,6]),columns=['variablename','lag=4','lag=3','lag=2','lag=1','lag=0'])\n",
    "spatlinreg_tsdfpval.iloc[0,0] = 'Constant'\n",
    "\n",
    "\n",
    "for varind in range(len(xvariable)):\n",
    "    for i in range(8,17):\n",
    "        spatlinreg_tsdf.iloc[varind*9+i-7,0] = 'Unemployment'+','+str(year[i])+', with respect to '+ variable[xvariable[varind]]\n",
    "        spatlinreg_tsdfpval.iloc[varind*9+i-7,0] = 'Unemployment'+','+str(year[i])+', with respect to '+ variable[xvariable[varind]]\n",
    "\n",
    "\n",
    "#iterate over years from year 2008 to 2020: (2008 corresponds to 4th column of stdvalue and 2020 corresponds to 17th column of stdvalue)\n",
    "for i in range(8,17):    \n",
    "    #compute all regression using initialized function for xmat and yvec, starting from 2012\n",
    "    yvec,xmat = Initializationtsyear(i,timelength)\n",
    "    #Get the yvec after considering spatial lags\n",
    "    yvec = yvec-APLEvec[i-8]*weightmat@yvec\n",
    "    resultsvec = sm.OLS(yvec,xmat).fit()\n",
    "    spatlinreg_tsdf.iloc[0,5] = resultsvec.params[0]\n",
    "    spatlinreg_tsdfpval.iloc[0,5]=resultsvec.pvalues[0]\n",
    "    #get the pvalue for coefficient between unemployment and earnings for year i \n",
    "    for varind in range(len(xvariable)):\n",
    "        for timeind in range(timelength+1):\n",
    "            spatlinreg_tsdf.iloc[varind*9+i-7,timeind+1] = resultsvec.params[varind*(timelength+1)+1+timeind]\n",
    "            spatlinreg_tsdfpval.iloc[varind*9+i-7,timeind+1]=resultsvec.pvalues[varind*(timelength+1)+1+timeind]\n",
    "            \n",
    "#show the result\n",
    "spatlinreg_tsdf \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22fff654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>lag=4</th>\n",
       "      <th>lag=3</th>\n",
       "      <th>lag=2</th>\n",
       "      <th>lag=1</th>\n",
       "      <th>lag=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Unemployment,2012, with respect to earnings</td>\n",
       "      <td>-0.106309</td>\n",
       "      <td>0.131456</td>\n",
       "      <td>-0.235974</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>-0.080183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Unemployment,2013, with respect to earnings</td>\n",
       "      <td>-0.110955</td>\n",
       "      <td>-0.115769</td>\n",
       "      <td>-0.206879</td>\n",
       "      <td>-0.228199</td>\n",
       "      <td>0.048036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Unemployment,2014, with respect to earnings</td>\n",
       "      <td>-0.178064</td>\n",
       "      <td>0.020351</td>\n",
       "      <td>-0.087916</td>\n",
       "      <td>-0.224512</td>\n",
       "      <td>-0.148459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Unemployment,2015, with respect to earnings</td>\n",
       "      <td>-0.019655</td>\n",
       "      <td>0.114213</td>\n",
       "      <td>-0.147501</td>\n",
       "      <td>-0.099318</td>\n",
       "      <td>-0.057228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Unemployment,2016, with respect to earnings</td>\n",
       "      <td>-0.219288</td>\n",
       "      <td>-0.121716</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.038142</td>\n",
       "      <td>0.246591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Unemployment,2017, with respect to earnings</td>\n",
       "      <td>0.086024</td>\n",
       "      <td>-0.056378</td>\n",
       "      <td>-0.069458</td>\n",
       "      <td>-0.053852</td>\n",
       "      <td>0.105961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Unemployment,2018, with respect to earnings</td>\n",
       "      <td>-0.024730</td>\n",
       "      <td>0.132399</td>\n",
       "      <td>-0.250699</td>\n",
       "      <td>0.219553</td>\n",
       "      <td>-0.166818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Unemployment,2019, with respect to earnings</td>\n",
       "      <td>-0.175097</td>\n",
       "      <td>0.161415</td>\n",
       "      <td>-0.242240</td>\n",
       "      <td>-0.135665</td>\n",
       "      <td>-0.077407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Unemployment,2020, with respect to earnings</td>\n",
       "      <td>0.096564</td>\n",
       "      <td>-0.325295</td>\n",
       "      <td>0.041773</td>\n",
       "      <td>-0.149237</td>\n",
       "      <td>-0.089788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variablename     lag=4     lag=3  \\\n",
       "109  Unemployment,2012, with respect to earnings -0.106309  0.131456   \n",
       "110  Unemployment,2013, with respect to earnings -0.110955 -0.115769   \n",
       "111  Unemployment,2014, with respect to earnings -0.178064  0.020351   \n",
       "112  Unemployment,2015, with respect to earnings -0.019655  0.114213   \n",
       "113  Unemployment,2016, with respect to earnings -0.219288 -0.121716   \n",
       "114  Unemployment,2017, with respect to earnings  0.086024 -0.056378   \n",
       "115  Unemployment,2018, with respect to earnings -0.024730  0.132399   \n",
       "116  Unemployment,2019, with respect to earnings -0.175097  0.161415   \n",
       "117  Unemployment,2020, with respect to earnings  0.096564 -0.325295   \n",
       "\n",
       "        lag=2     lag=1     lag=0  \n",
       "109 -0.235974  0.113228 -0.080183  \n",
       "110 -0.206879 -0.228199  0.048036  \n",
       "111 -0.087916 -0.224512 -0.148459  \n",
       "112 -0.147501 -0.099318 -0.057228  \n",
       "113  0.022911  0.038142  0.246591  \n",
       "114 -0.069458 -0.053852  0.105961  \n",
       "115 -0.250699  0.219553 -0.166818  \n",
       "116 -0.242240 -0.135665 -0.077407  \n",
       "117  0.041773 -0.149237 -0.089788  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we return the coefficient for betas for earning variables:\n",
    "spatlinreg_tsdf[109:118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e378384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variablename</th>\n",
       "      <th>lag=4</th>\n",
       "      <th>lag=3</th>\n",
       "      <th>lag=2</th>\n",
       "      <th>lag=1</th>\n",
       "      <th>lag=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Unemployment,2012, with respect to earnings</td>\n",
       "      <td>0.235921</td>\n",
       "      <td>0.327891</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>0.397534</td>\n",
       "      <td>0.582354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Unemployment,2013, with respect to earnings</td>\n",
       "      <td>0.421590</td>\n",
       "      <td>0.459869</td>\n",
       "      <td>0.181602</td>\n",
       "      <td>0.191733</td>\n",
       "      <td>0.769186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Unemployment,2014, with respect to earnings</td>\n",
       "      <td>0.144847</td>\n",
       "      <td>0.869130</td>\n",
       "      <td>0.536260</td>\n",
       "      <td>0.081477</td>\n",
       "      <td>0.337151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Unemployment,2015, with respect to earnings</td>\n",
       "      <td>0.861226</td>\n",
       "      <td>0.390507</td>\n",
       "      <td>0.210010</td>\n",
       "      <td>0.490759</td>\n",
       "      <td>0.660404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Unemployment,2016, with respect to earnings</td>\n",
       "      <td>0.123566</td>\n",
       "      <td>0.364435</td>\n",
       "      <td>0.893257</td>\n",
       "      <td>0.803925</td>\n",
       "      <td>0.079005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Unemployment,2017, with respect to earnings</td>\n",
       "      <td>0.549593</td>\n",
       "      <td>0.744137</td>\n",
       "      <td>0.657653</td>\n",
       "      <td>0.741320</td>\n",
       "      <td>0.506536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Unemployment,2018, with respect to earnings</td>\n",
       "      <td>0.879040</td>\n",
       "      <td>0.409417</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.186026</td>\n",
       "      <td>0.174639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Unemployment,2019, with respect to earnings</td>\n",
       "      <td>0.231451</td>\n",
       "      <td>0.260064</td>\n",
       "      <td>0.098079</td>\n",
       "      <td>0.253136</td>\n",
       "      <td>0.340218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Unemployment,2020, with respect to earnings</td>\n",
       "      <td>0.574234</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.777596</td>\n",
       "      <td>0.153396</td>\n",
       "      <td>0.370648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    variablename     lag=4     lag=3  \\\n",
       "109  Unemployment,2012, with respect to earnings  0.235921  0.327891   \n",
       "110  Unemployment,2013, with respect to earnings  0.421590  0.459869   \n",
       "111  Unemployment,2014, with respect to earnings  0.144847  0.869130   \n",
       "112  Unemployment,2015, with respect to earnings  0.861226  0.390507   \n",
       "113  Unemployment,2016, with respect to earnings  0.123566  0.364435   \n",
       "114  Unemployment,2017, with respect to earnings  0.549593  0.744137   \n",
       "115  Unemployment,2018, with respect to earnings  0.879040  0.409417   \n",
       "116  Unemployment,2019, with respect to earnings  0.231451  0.260064   \n",
       "117  Unemployment,2020, with respect to earnings  0.574234  0.073636   \n",
       "\n",
       "        lag=2     lag=1     lag=0  \n",
       "109  0.074729  0.397534  0.582354  \n",
       "110  0.181602  0.191733  0.769186  \n",
       "111  0.536260  0.081477  0.337151  \n",
       "112  0.210010  0.490759  0.660404  \n",
       "113  0.893257  0.803925  0.079005  \n",
       "114  0.657653  0.741320  0.506536  \n",
       "115  0.114133  0.186026  0.174639  \n",
       "116  0.098079  0.253136  0.340218  \n",
       "117  0.777596  0.153396  0.370648  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we return the pvalue for betas for earning variables:\n",
    "spatlinreg_tsdfpval[109:118]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
